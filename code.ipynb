{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2\n",
    "# Introducción \n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tabla de contenidos</h2>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px; background-color: #FFECB3; color: #FFB300;\">\n",
    "<ol>\n",
    "    <li> Validación cruzada </li>\n",
    "    <li> Regresión lineal simple </li>\n",
    "    <li> Regresión lineal múltiple </li>\n",
    "    <li> Regresión no lineal </li>\n",
    "    <li> Regresión lineal con regularizacion </li>\n",
    "    <li> Comparación de los resultados obtenidos con los diferentes modelos </li>\n",
    " \n",
    "   \n",
    "</ol>\n",
    "\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones de librerías necesarias\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection   \n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la regresión, vamos a utilizar como variable dependiente la CPK, nuestro objetivo será predecir los niveles de CPK\n",
    "\n",
    "# Cargamos la base de datos\n",
    "data = pd.read_csv(\"entrenamiento.csv\")\n",
    "\n",
    "# Definimos las variables de entrada y de salida\n",
    "data_input = data.drop(['creatinine_phosphokinase','DEATH_EVENT'], axis=1) \n",
    "data_output = data['creatinine_phosphokinase']\n",
    "\n",
    "# Vamos a comprobar que variable permite una mejor estimacion de la variable dependiente\n",
    "# Primero dividimos el conjunto de entrenamiento en dos partes, una para entrenar y otra para validar\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_input, data_output, test_size=0.3, random_state = 777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.426377</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.433949</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.301510</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.387736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.233717</td>\n",
       "      <td>0.500783</td>\n",
       "      <td>0.496461</td>\n",
       "      <td>0.244455</td>\n",
       "      <td>0.500783</td>\n",
       "      <td>0.164162</td>\n",
       "      <td>0.214593</td>\n",
       "      <td>0.194123</td>\n",
       "      <td>0.489706</td>\n",
       "      <td>0.458861</td>\n",
       "      <td>0.293012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296739</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.387882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.441848</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age    anaemia   diabetes  ejection_fraction  \\\n",
       "count  88.000000  88.000000  88.000000          88.000000   \n",
       "mean    0.426377   0.454545   0.420455           0.433949   \n",
       "std     0.233717   0.500783   0.496461           0.244455   \n",
       "min     0.000000   0.000000   0.000000           0.000000   \n",
       "25%     0.272727   0.000000   0.000000           0.270833   \n",
       "50%     0.387882   0.000000   0.000000           0.437500   \n",
       "75%     0.545455   1.000000   1.000000           0.583333   \n",
       "max     1.000000   1.000000   1.000000           1.000000   \n",
       "\n",
       "       high_blood_pressure  platelets  serum_creatinine  serum_sodium  \\\n",
       "count            88.000000  88.000000         88.000000     88.000000   \n",
       "mean              0.454545   0.392704          0.301510      0.597403   \n",
       "std               0.500783   0.164162          0.214593      0.194123   \n",
       "min               0.000000   0.000000          0.000000      0.000000   \n",
       "25%               0.000000   0.296739          0.190476      0.476190   \n",
       "50%               0.000000   0.391304          0.238095      0.619048   \n",
       "75%               1.000000   0.441848          0.345238      0.714286   \n",
       "max               1.000000   1.000000          1.000000      1.000000   \n",
       "\n",
       "             sex    smoking       time  \n",
       "count  88.000000  88.000000  88.000000  \n",
       "mean    0.613636   0.295455   0.387736  \n",
       "std     0.489706   0.458861   0.293012  \n",
       "min     0.000000   0.000000   0.000000  \n",
       "25%     0.000000   0.000000   0.101887  \n",
       "50%     1.000000   0.000000   0.313208  \n",
       "75%     1.000000   1.000000   0.679245  \n",
       "max     1.000000   1.000000   1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizamos los datos del conjunto train\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_res_train = X_train.copy()\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Todos los valores están en el rango [0,1]\n",
    "data_minmax = scaler.fit_transform(X_res_train)\n",
    "\n",
    "scaled_train = pd.DataFrame(data_minmax, columns=X_res_train.columns)\n",
    "scaled_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.417544</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.398026</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.411654</td>\n",
       "      <td>0.322989</td>\n",
       "      <td>0.550937</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.354121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.243465</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>0.239493</td>\n",
       "      <td>0.503897</td>\n",
       "      <td>0.215505</td>\n",
       "      <td>0.247220</td>\n",
       "      <td>0.157426</td>\n",
       "      <td>0.471069</td>\n",
       "      <td>0.446258</td>\n",
       "      <td>0.291629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.056522</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288043</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406911</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.595455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529891</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.583962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age    anaemia   diabetes  ejection_fraction  \\\n",
       "count  38.000000  38.000000  38.000000          38.000000   \n",
       "mean    0.417544   0.500000   0.500000           0.398026   \n",
       "std     0.243465   0.506712   0.506712           0.239493   \n",
       "min     0.000000   0.000000   0.000000          -0.041667   \n",
       "25%     0.181818   0.000000   0.000000           0.270833   \n",
       "50%     0.436364   0.500000   0.500000           0.375000   \n",
       "75%     0.595455   1.000000   1.000000           0.479167   \n",
       "max     1.000000   1.000000   1.000000           0.895833   \n",
       "\n",
       "       high_blood_pressure  platelets  serum_creatinine  serum_sodium  \\\n",
       "count            38.000000  38.000000         38.000000     38.000000   \n",
       "mean              0.447368   0.411654          0.322989      0.550937   \n",
       "std               0.503897   0.215505          0.247220      0.157426   \n",
       "min               0.000000  -0.056522         -0.047619      0.190476   \n",
       "25%               0.000000   0.288043          0.190476      0.440476   \n",
       "50%               0.000000   0.406911          0.257143      0.571429   \n",
       "75%               1.000000   0.529891          0.404762      0.666667   \n",
       "max               1.000000   0.843478          1.142857      0.857143   \n",
       "\n",
       "             sex    smoking       time  \n",
       "count  38.000000  38.000000  38.000000  \n",
       "mean    0.684211   0.263158   0.354121  \n",
       "std     0.471069   0.446258   0.291629  \n",
       "min     0.000000   0.000000  -0.007547  \n",
       "25%     0.000000   0.000000   0.100943  \n",
       "50%     1.000000   0.000000   0.273585  \n",
       "75%     1.000000   0.750000   0.583962  \n",
       "max     1.000000   1.000000   0.898113  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizamos el conjunto de test\n",
    "\n",
    "X_res_test = X_test.copy()\n",
    "\n",
    "# Todos los valores están en el rango [0,1]\n",
    "data_minmax = scaler.transform(X_res_test)\n",
    "\n",
    "scaled_test = pd.DataFrame(data_minmax, columns=X_res_test.columns)\n",
    "scaled_test.describe()\n",
    "\n",
    "# Comprobamos que la normalizacion  del test esta bien al observar que los valores maximos y minimos no son solamnete 1 y 0 (hemos utilizado el scaler del train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresor lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               age   anaemia  diabetes  ejection_fraction  \\\n",
      "age                       1.000000 -0.022076 -0.046849           0.161716   \n",
      "anaemia                  -0.022076  1.000000 -0.130291           0.093537   \n",
      "diabetes                 -0.046849 -0.130291  1.000000          -0.088185   \n",
      "ejection_fraction         0.161716  0.093537 -0.088185           1.000000   \n",
      "high_blood_pressure       0.017207 -0.100000  0.147103          -0.117722   \n",
      "platelets                -0.044028 -0.208629  0.075807           0.026037   \n",
      "serum_creatinine          0.169503  0.024839 -0.032745          -0.279697   \n",
      "serum_sodium             -0.084807  0.017915 -0.069185           0.233609   \n",
      "sex                       0.278750 -0.072436 -0.127866          -0.135614   \n",
      "smoking                   0.283108 -0.140967 -0.097472          -0.127167   \n",
      "time                     -0.139400 -0.070352  0.054342          -0.023411   \n",
      "creatinine_phosphokinase  0.173839 -0.204416  0.151376          -0.064592   \n",
      "\n",
      "                          high_blood_pressure  platelets  serum_creatinine  \\\n",
      "age                                  0.017207  -0.044028          0.169503   \n",
      "anaemia                             -0.100000  -0.208629          0.024839   \n",
      "diabetes                             0.147103   0.075807         -0.032745   \n",
      "ejection_fraction                   -0.117722   0.026037         -0.279697   \n",
      "high_blood_pressure                  1.000000   0.139025          0.007013   \n",
      "platelets                            0.139025   1.000000         -0.062893   \n",
      "serum_creatinine                     0.007013  -0.062893          1.000000   \n",
      "serum_sodium                        -0.128474   0.033483         -0.234205   \n",
      "sex                                 -0.119306  -0.154760          0.040276   \n",
      "smoking                             -0.090947  -0.019341          0.016236   \n",
      "time                                -0.135679   0.043744         -0.132289   \n",
      "creatinine_phosphokinase             0.077864   0.136153          0.044636   \n",
      "\n",
      "                          serum_sodium       sex   smoking      time  \\\n",
      "age                          -0.084807  0.278750  0.283108 -0.139400   \n",
      "anaemia                       0.017915 -0.072436 -0.140967 -0.070352   \n",
      "diabetes                     -0.069185 -0.127866 -0.097472  0.054342   \n",
      "ejection_fraction             0.233609 -0.135614 -0.127167 -0.023411   \n",
      "high_blood_pressure          -0.128474 -0.119306 -0.090947 -0.135679   \n",
      "platelets                     0.033483 -0.154760 -0.019341  0.043744   \n",
      "serum_creatinine             -0.234205  0.040276  0.016236 -0.132289   \n",
      "serum_sodium                  1.000000 -0.037163  0.029606  0.100984   \n",
      "sex                          -0.037163  1.000000  0.462694 -0.091441   \n",
      "smoking                       0.029606  0.462694  1.000000 -0.060165   \n",
      "time                          0.100984 -0.091441 -0.060165  1.000000   \n",
      "creatinine_phosphokinase     -0.087331  0.001460  0.057584 -0.008991   \n",
      "\n",
      "                          creatinine_phosphokinase  \n",
      "age                                       0.173839  \n",
      "anaemia                                  -0.204416  \n",
      "diabetes                                  0.151376  \n",
      "ejection_fraction                        -0.064592  \n",
      "high_blood_pressure                       0.077864  \n",
      "platelets                                 0.136153  \n",
      "serum_creatinine                          0.044636  \n",
      "serum_sodium                             -0.087331  \n",
      "sex                                       0.001460  \n",
      "smoking                                   0.057584  \n",
      "time                                     -0.008991  \n",
      "creatinine_phosphokinase                  1.000000  \n"
     ]
    }
   ],
   "source": [
    "datos_a_correlar = scaled_train.copy()\n",
    "datos_a_correlar[\"creatinine_phosphokinase\"] = Y_train\n",
    "\n",
    "# Mostramos la matriz de correlacion para saber que datos están mas correlados con la variable dependiente. No debemos coger valores muy altos ya que se producira multicolinealidad.\n",
    "correlacion = datos_a_correlar.corr()\n",
    "print(correlacion)\n",
    "# Vemos que platelets, age, o high blood preassure son buenas opciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False False False False  True  True]\n",
      "Caracteristicas seleccionadas por el selector: Index(['anaemia', 'smoking', 'time'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Tambien vamos a realizar un analisis usando SelectKBest\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Aplicamos el metodo\n",
    "selector = SelectKBest(score_func=f_regression, k=3) # k es el numero de variables que queremos seleccionar\n",
    "selector.fit(scaled_train, Y_train)\n",
    "\n",
    "# Mostramos las variables seleccionadas\n",
    "indices_seleccionados = selector.get_support()\n",
    "print(indices_seleccionados)\n",
    "\n",
    "# Mostramos los nombres de las variables seleccionadas\n",
    "caracteristicas = scaled_train.columns\n",
    "print(f\"Caracteristicas seleccionadas por el selector: {caracteristicas[indices_seleccionados]}\")\n",
    "\n",
    "#print(selector.pvalues_ < 0.05) El único pvalor < 0.05 es el de la variable time, pero también hemos podido observar\n",
    "# en la matriz de correlación, que no está nada correlada con la variable dependiente, por lo que no la vamos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor del intercepto: 533.4212494530161\n",
      "Valor del coeficiente w1: -234.17128695040304\n",
      "R Squared: 0.03658915726683587 \n",
      "Mean Squared Error:265594.13992709015 \n",
      "Raíz Cuadrada del MSE: 515.3582636643077 \n",
      "R Squared con validación cruzada: 0.18226136966417417 \n",
      "Root Mean Squared Error con validación cruzada: 594.7079284689911\n"
     ]
    }
   ],
   "source": [
    "# Creamos dos listas vacias para guardar los resultados de las metricas\n",
    "r2_results=[] # error cuadratico medio\n",
    "mse_results=[] # MSE\n",
    "rmse_results_cv = [] # RMSE con validacion cruzada\n",
    "r2_results_cv = [] # R^2 con validacion cruzada\n",
    "\n",
    "# Regresión lineal simple\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Entrenamos el modelo utilizando los datos de train\n",
    "regressor = regressor.fit(np.array(scaled_train['serum_creatinine']).reshape(-1, 1), Y_train)\n",
    "\n",
    "# Mostramos el valor del intercepto (wo)\n",
    "w0 = regressor.intercept_\n",
    "print(f\"Valor del intercepto: {w0}\")\n",
    "\n",
    "# Mostramos el valor de los coeficientes (w1)\n",
    "w1 = regressor.coef_ # Del resultado podemos decir que a medida que aumenta el valor de CPK, disminuyen los valores de serum_creatinine\n",
    "print(f\"Valor del coeficiente w1: {w1[0]}\")\n",
    "\n",
    "# Obtenemos el valor predicho para el conjunto de test\n",
    "y_pred = regressor.predict(np.array(scaled_test['serum_creatinine']).reshape(-1,1))\n",
    "\n",
    "#  Calculamos el error cuadrático medio entre el valor predicho y el valor real\n",
    "mse_l=metrics.mean_squared_error(Y_test, y_pred)\n",
    "mse_results.append(mse_l)\n",
    "\n",
    "# Calculamos R^2 entre el valor predicho y el valor real\n",
    "r_squared_l=metrics.r2_score(Y_test, y_pred)\n",
    "r2_results.append(r_squared_l)\n",
    "\n",
    "# Calculamos el error cuadrático medio entre el valor predicho y el valor real con validación cruzada\n",
    "rmse_cv = cross_val_score(regressor, np.array(scaled_train['serum_creatinine']).reshape(-1,1), Y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_results_cv.append(np.mean(np.sqrt(np.abs(rmse_cv))))\n",
    "\n",
    "# Calculamos R^2 entre el valor predicho y el valor real con validación cruzada\n",
    "r2_cv = cross_val_score(regressor, np.array(scaled_train['serum_creatinine']).reshape(-1,1), Y_train, scoring='r2', cv=3)\n",
    "r2_results_cv.append(np.mean(np.abs(r2_cv)))\n",
    "\n",
    "print(f'R Squared: {r_squared_l} \\nMean Squared Error:{mse_l} \\nRaíz Cuadrada del MSE: {np.sqrt(mse_l)} \\nR Squared con validación cruzada: {np.mean(np.abs(r2_cv))} \\nRoot Mean Squared Error con validación cruzada: {np.mean(np.sqrt(np.abs(rmse_cv)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En la gráfica se puede observar que la recta de regresión se ajusta correctamente a los datos, aunque estos se encuentran muy dispersos, \n",
      "provocando que el error cuadrático medio sea muy alto.\n"
     ]
    }
   ],
   "source": [
    "# Visualización de resultados\n",
    "X = np.linspace(0,1.5,100)\n",
    "Y = w0 + w1*X # Recta de regresión\n",
    "\n",
    "plt.scatter(scaled_test['serum_creatinine'],Y_test,color='g')\n",
    "plt.plot(X, Y,color='r')\n",
    "plt.xlabel('serum_creatinine')\n",
    "plt.ylabel(\"CPK\")\n",
    "plt.show()\n",
    "\n",
    "print(\"En la gráfica se puede observar que la recta de regresión se ajusta correctamente a los datos, aunque estos se encuentran muy dispersos, \\nprovocando que el error cuadrático medio sea muy alto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cuestiones \n",
    "\n",
    "a) ¿Cuál es la variable dependiente que podría considerar para abordar un problema de regresión lineal?\n",
    "\n",
    "Podemos considerar calquiera que sea continua.\n",
    "\n",
    "b) ¿Qué variable es la que permite mejor estimar la variable dependiente? Puede ayudarse en el valor del coeficiente de correlación, así como en alguna medida de prestación que considere adecuada para evaluar las prestaciones del regresor.\n",
    "\n",
    "En nuestro caso, nos hemos basado en la matriz de correlación, el selector de caracteristicas, y los valores de R squared y MSE. Primero, hemos visto que variables eran las más significantes utilizando el selector, después, hemos hecho un filtrado utilizando la información de la matriz de correlación; de forma que hemos dejado las características cuya correlación con la variable dependiente era mayor. Una vez hecho esto, hemos probado a predecir la salida utilizando distintas características, seleccionando finalente las que devolvian un menor MSE y un mayor R squared.\n",
    "\n",
    "c) Indique si las prestaciones obtenidas en el conjunto de test cambian tras normalizar las variables.\n",
    "\n",
    "No deberían cambiar despues de realizar la normalización, ya que tenemos solo una variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresor lineal multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor del intercepto: 273.8326083151454\n",
      "Valor de los coeficientes: [ 735.67990161 -177.29891599  -68.55365463]\n",
      "R Squared: 0.05977838334376262 \n",
      "Mean Squared Error:259201.30907830753 \n",
      "Raíz cuadrada de MSE: 509.1181680890081 \n",
      "R Squared con validación cruzada: 0.19172524446569691 \n",
      "Raíz del Mean Squared Error con validación cruzada: 576.6843776351643\n",
      "Al aumentar el número de variables, la predicción se ha realizado de una manera mejor (ya que el MSE ha disminuido y el R squared ha aumentado), ya que estamos usando más información para predecir los valores de CPK, sin embargo \n",
      "la predicción sigue sin ser muy buena, ya que las variables no estan demasiado correlacionadas con la variable dependiente ni entre ellas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Regresión lineal simple multiple\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Entrenamos el modelo utilizando los datos de train\n",
    "col = [\"time\", \"age\", \"serum_creatinine\"] # Basándonos en los resultados de la matriz de correlación y del selector de variables, hemos decidido usar estas tres variables,\n",
    "# ya que time es la variable con menor pvalor, y las otras dos son las que mejor se correlacionan con esta variable\n",
    "regressor = regressor.fit(scaled_train[col], Y_train)\n",
    "\n",
    "# Mostramos el valor del intercepto (wo)\n",
    "print(f\"Valor del intercepto: {regressor.intercept_}\")\n",
    "\n",
    "# Mostramos el valor de los coeficientes\n",
    "print(f\"Valor de los coeficientes: {regressor.coef_}\") \n",
    "# Del resultado podemos decir que a medida que aumenta el valor de CPK, disminuyen los valores de age y de serum_creatinine, mientras que los valores de time aumentan\n",
    "\n",
    "# Obtenemos el valor predicho para el conjunto de test\n",
    "y_pred = regressor.predict(np.array(scaled_test[col]))\n",
    "\n",
    "#  Calculamos el error cuadrático medio\n",
    "mse_m=metrics.mean_squared_error(Y_test, y_pred)\n",
    "mse_results.append(mse_m)\n",
    "\n",
    "# Calculamos R^2\n",
    "r_squared_m=metrics.r2_score(Y_test, y_pred)\n",
    "r2_results.append(r_squared_m)\n",
    "\n",
    "# Calculamos el error cuadrático medio con validación cruzada\n",
    "rmse_cv = cross_val_score(regressor, scaled_train[col], Y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_results_cv.append(np.mean(np.sqrt(np.abs(rmse_cv))))\n",
    "\n",
    "# Calculamos R^2 con validación cruzada\n",
    "r2_cv = cross_val_score(regressor, scaled_train[col], Y_train, scoring='r2', cv=3)\n",
    "r2_results_cv.append(np.mean(np.abs(r2_cv)))\n",
    "\n",
    "print(f'R Squared: {r_squared_m} \\nMean Squared Error:{mse_m} \\nRaíz cuadrada de MSE: {np.sqrt(mse_m)} \\nR Squared con validación cruzada: {np.mean(np.abs(r2_cv))} \\nRaíz del Mean Squared Error con validación cruzada: {np.mean(np.sqrt(np.abs(rmse_cv)))}')\n",
    "print(\"Al aumentar el número de variables, la predicción se ha realizado de una manera mejor (ya que el MSE ha disminuido y el R squared ha aumentado), ya que estamos usando más información para predecir los valores de CPK, sin embargo \\nla predicción sigue sin ser muy buena, ya que las variables no estan demasiado correlacionadas con la variable dependiente ni entre ellas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion no lineal\n",
    "\n",
    "#### Regresión polinómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared: -2.875307347986802 \n",
      "Mean Squared Error:1068348.9082619355 \n",
      "Raíz cuadrada de MSE: 1033.6096498494658 \n",
      "Grado óptimo: 1 \n",
      "R Squared con validación cruzada: -0.783816476784636 \n",
      "Raíz del Mean Squared Error con validación cruzada: 717.4033850819366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Usamos validación cruzada para encontrar el parámetro del grado del polinomio, asi evitamos el overfitting\n",
    "cv_degree_scores=[]\n",
    "d_values = range(1,6,1) # Grados de polinommio entre 1 y 6, utilizamos este rango ya que con un mayor grado, aumentan las probabilidades de cometer overfitting, además, la carga \n",
    "# computacional aumenta mucho, por lo que el modelo se hace mucho mas lento\n",
    "for d in d_values:\n",
    "    poly_reg = PolynomialFeatures(degree=d)\n",
    "    X_train_poly = poly_reg.fit_transform(scaled_train)\n",
    "    X_test_poly = poly_reg.transform(scaled_test)\n",
    "    # Transformamos los conjuntos de entrenamiento y test para tener variables polinomicas\n",
    "    pol_reg = LinearRegression()\n",
    "    scores= cross_val_score(pol_reg, X_train_poly, Y_train, cv=3, scoring='neg_mean_squared_error') # Con el parametro cv = 3, estamos haciendo validacion cruzada con 3 particiones\n",
    "    # Aqui se usa el error negativo, por eso va para abajo el grafico\n",
    "    # Calculamos score en el sector de validacion y guardamos el valor de la media\n",
    "    cv_degree_scores.append(scores.mean())\n",
    "    \n",
    "# Graficamos los resultados\n",
    "plt.plot(d_values, cv_degree_scores)\n",
    "plt.xlabel('Grado')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()\n",
    "\n",
    "# Entrenamos el modelo y predecimos con el grado del polinomio obtenido con cross-validation\n",
    "# En la grafica anterior podemos observar que el grado optimo es 1, sin embargo, ya hemos realizado una predicción lineal. Por tanto, en este caso vamos a realizar \n",
    "# una predicción con polinomio de grado 4, para comprobar que el resultado es peor.\n",
    "poly_reg = PolynomialFeatures(degree=4)\n",
    "X_train_poly = poly_reg.fit_transform(scaled_train)\n",
    "X_test_poly = poly_reg.transform(scaled_test)\n",
    "\n",
    "# Entremos y predecimos\n",
    "pol_reg = LinearRegression()\n",
    "pol_reg.fit(X_train_poly, Y_train)\n",
    "y_pred_pol=pol_reg.predict(X_test_poly)\n",
    "\n",
    "# Calculamos el error cuadrático medio\n",
    "mse_pol=metrics.mean_squared_error(Y_test, y_pred_pol)\n",
    "mse_results.append(mse_pol)\n",
    "\n",
    "# Calculamos R^2\n",
    "r_squared_pol=metrics.r2_score(Y_test, y_pred_pol)\n",
    "r2_results.append(r_squared_pol)\n",
    "\n",
    "# Calculamos el error cuadrático medio con validación cruzada\n",
    "rmse_cv = cross_val_score(pol_reg, X_train_poly, Y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_results_cv.append(np.mean(np.sqrt(np.abs(rmse_cv))))\n",
    "\n",
    "# Calculamos R^2 con validación cruzada\n",
    "r2_cv = cross_val_score(pol_reg, X_train_poly, Y_train, scoring='r2', cv=3)\n",
    "r2_results_cv.append(np.mean(np.abs(r2_cv)))\n",
    "\n",
    "# Seleccionamos el valor máximo \n",
    "print(f\"R Squared: {r_squared_pol} \\nMean Squared Error:{mse_pol} \\nRaíz cuadrada de MSE: {np.sqrt(mse_pol)} \\nGrado óptimo: {np.array(d_values)[cv_degree_scores.index(np.array(cv_degree_scores).max())]} \\nR Squared con validación cruzada: {np.mean(r2_cv)} \\nRaíz del Mean Squared Error con validación cruzada: {np.mean(np.sqrt(np.abs(rmse_cv)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logaritmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared: 0.03878481379272447 \n",
      "Mean Squared Error:264988.8389685559 \n",
      "Raíz cuadrada de MSE: 514.7706663831535 \n",
      "R Squared con validación cruzada: -0.19496856147595495 \n",
      "Raíz del Mean Squared Error con validación cruzada: 597.5076548472955\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como se puede observar, la predicción es bastante mala, ya que los datos están muy dispersos, y la recta de regresión no se ajusta bien a los datos.\n"
     ]
    }
   ],
   "source": [
    "# Aplica una transformación logarítmica a los datos\n",
    "xtrain_log = round(np.log(scaled_train + 1), 6) # Sumamos 1 dentro del logaritmo para que no de error al ser 0\n",
    "\n",
    "# Crea un modelo de regresión lineal\n",
    "log_reg = LinearRegression()\n",
    "\n",
    "# Ajusta el modelo a los datos\n",
    "log_reg.fit(np.array(xtrain_log[\"serum_creatinine\"]).reshape(-1, 1), Y_train)\n",
    "\n",
    "# Realiza predicciones utilizando el modelo\n",
    "\n",
    "xtest_log = np.log(scaled_test + 1) \n",
    "\n",
    "y_pred = log_reg.predict(np.array(xtest_log[\"serum_creatinine\"]).reshape(-1, 1))\n",
    "\n",
    "a = log_reg.coef_[0]\n",
    "b = log_reg.intercept_\n",
    "\n",
    "# Calculamos el error cuadrático medio\n",
    "mse_log=metrics.mean_squared_error(Y_test, y_pred)\n",
    "mse_results.append(mse_log)\n",
    "\n",
    "# Calculamos R^2\n",
    "r_squared_log=metrics.r2_score(Y_test, y_pred)\n",
    "r2_results.append(r_squared_log)\n",
    "\n",
    "# Calculamos el error cuadrático medio con validación cruzada\n",
    "rmse_cv = cross_val_score(log_reg, np.array(xtrain_log[\"serum_creatinine\"]).reshape(-1, 1), Y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_results_cv.append(np.mean(np.sqrt(np.abs(rmse_cv))))\n",
    "\n",
    "# Calculamos R^2 con validación cruzada\n",
    "r2_cv = cross_val_score(log_reg, np.array(xtrain_log[\"serum_creatinine\"]).reshape(-1, 1), Y_train, scoring='r2', cv=3)\n",
    "r2_results_cv.append(np.mean(r2_cv))\n",
    "\n",
    "print(f'R Squared: {r_squared_log} \\nMean Squared Error:{mse_log} \\nRaíz cuadrada de MSE: {np.sqrt(mse_log)} \\nR Squared con validación cruzada: {np.mean(r2_cv)} \\nRaíz del Mean Squared Error con validación cruzada: {np.mean(np.sqrt(np.abs(rmse_cv)))}')\n",
    "\n",
    "\n",
    "# Construimos la funcion logaritmica\n",
    "x = np.linspace(0,5,100)\n",
    "f = a*np.log(x + 1) + b\n",
    "\n",
    "# Dibuja los datos y la línea de regresión\n",
    "plt.scatter(scaled_train[\"serum_creatinine\"], Y_train, label='Datos reales')\n",
    "plt.plot(x, f, label='Regresión logarítmica', color='red')\n",
    "plt.xlim(0,2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Como se puede observar, la predicción es bastante mala, ya que los datos están muy dispersos, y la recta de regresión no se ajusta bien a los datos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión exponencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared: 0.03450545921318693 \n",
      "Mean Squared Error:266168.5760532776 \n",
      "Raíz cuadrada de MSE: 515.9152799183967 \n",
      "R Squared con validación cruzada: 0.156857868023905 \n",
      "Raíz del Mean Squared Error con validación cruzada: 589.1503080670219\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Transformamos los datos\n",
    "xtrain_exp = np.exp(scaled_train[\"serum_creatinine\"])\n",
    "\n",
    "# Modelo de regresión lineal\n",
    "exp_reg = LinearRegression()\n",
    "\n",
    "# Ajustamos el modelo a los datos\n",
    "exp_reg.fit(np.array(xtrain_exp).reshape(-1, 1), Y_train)\n",
    "\n",
    "# Realizamos predicciones utilizando el modelo\n",
    "xtest_exp = np.exp(scaled_test[\"serum_creatinine\"])\n",
    "\n",
    "y_pred = exp_reg.predict(np.array(xtest_exp).reshape(-1, 1))\n",
    "\n",
    "a_optimizado = exp_reg.coef_[0]\n",
    "b_optimizado = exp_reg.intercept_\n",
    "\n",
    "# Calcula el error cuadrático medio\n",
    "mse_exp=metrics.mean_squared_error(Y_test, y_pred)\n",
    "mse_results.append(mse_exp)\n",
    "\n",
    "# Calculamos R^2\n",
    "r_squared_exp=metrics.r2_score(Y_test, y_pred)\n",
    "r2_results.append(r_squared_exp)\n",
    "\n",
    "# Calculamos el error cuadrático medio con validación cruzada\n",
    "rmse_cv = cross_val_score(exp_reg, np.array(xtrain_exp).reshape(-1, 1), Y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_results_cv.append(np.mean(np.sqrt(np.abs(rmse_cv))))\n",
    "\n",
    "# Calculamos R^2 con validación cruzada\n",
    "r2_cv = cross_val_score(exp_reg, np.array(xtrain_exp).reshape(-1, 1), Y_train, scoring='r2', cv=3)\n",
    "r2_results_cv.append(np.mean(r2_cv))\n",
    "\n",
    "print(f'R Squared: {r_squared_exp} \\nMean Squared Error:{mse_exp} \\nRaíz cuadrada de MSE: {np.sqrt(mse_exp)} \\nR Squared con validación cruzada: {np.mean(np.abs(r2_cv))} \\nRaíz del Mean Squared Error con validación cruzada: {np.mean(np.sqrt(np.abs(rmse_cv)))}')\n",
    "# Nos devuelve el mismo error que en la logaritmica porque se puede ajustar la exponencial como una logaritmica\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "f = a_optimizado * np.exp(b_optimizado * x) # Función exponencial\n",
    "\n",
    "# Gráfico de los datos y la curva ajustada\n",
    "plt.scatter(scaled_train[\"serum_creatinine\"], Y_train, label='Datos reales')\n",
    "plt.plot(x, f, 'r-', label='Regresión exponencial')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,3000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluya qué funciones no lineales (logarítmica, inversa, cuadrática, cúbica, de\n",
    "potencia, exponencial, etc.) se ajustan mejor a los datos disponibles.\n",
    "\n",
    "El modelo que mejor se ajusta es el modelo de regresión logarítmica. Ya que es el que mejores figuras de mérito tiene.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion lineal con regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor valor de alpha es: 10\n",
      "El valor de los coeficientes para cada una de las variables es: [ -69.07951699 -176.40690222 -111.28159488  -94.76767017  -45.86756245\n",
      "  -59.02509774  -53.28812775   65.16472156  115.75122215 -191.34701114\n",
      "  308.91639551]\n",
      "R Squared: -0.02948452357582987 \n",
      "Mean Squared Error:283809.40350606287 \n",
      "Raíz cuadrada de MSE: 532.7376497921495 \n",
      "R Squared con validación cruzada: 0.029308714410078245 \n",
      "Raíz del Mean Squared Error con validación cruzada: 544.90691046503\n"
     ]
    }
   ],
   "source": [
    "# Regresión Ridge \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "\n",
    "# Valores para alpha\n",
    "parameters = {\"alpha\":[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20,30]}\n",
    "# alpha es el parametro de regularizacion, cuanto mas grande sea, mas penaliza los coeficientes mas grandes, cogemos valores extremos para compararlos\n",
    "\n",
    "# Seleccionamos el mejor valor de alpha\n",
    "ridge_regression = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3) \n",
    "ridge_regression.fit(scaled_train, Y_train) \n",
    "print(f\"El mejor valor de alpha es: {ridge_regression.best_params_['alpha']}\")\n",
    "# Como ya sabemos el mejor valor de alpha, creamos el modelo con ese valor\n",
    "\n",
    "# Entrenamos\n",
    "\n",
    "ridge = Ridge(alpha=ridge_regression.best_params_['alpha'])\n",
    "ridge_regression = ridge.fit(scaled_train, Y_train)\n",
    "\n",
    "print(f\"El valor de los coeficientes para cada una de las variables es: {ridge_regression.coef_}\")\n",
    "# Las columnas son: ['age', 'anaemia', 'diabetes', 'ejection_fraction','high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium','sex', 'smoking', 'time']\n",
    "# En este caso, las caracteristicas mas relevantes son anaemia, diabetes, sex, smoking y time. \n",
    "\n",
    "# Se obtiene la salida predicha\n",
    "y_pred_ridge = ridge_regression.predict(scaled_test)\n",
    "\n",
    "# Calculamos el error cuadrático medio\n",
    "mse_ridge=metrics.mean_squared_error(Y_test, y_pred_ridge)\n",
    "mse_results.append(mse_ridge)\n",
    "\n",
    "# Calculamos R2\n",
    "r_squared_ridge=metrics.r2_score(Y_test, y_pred_ridge)\n",
    "r2_results.append(r_squared_ridge)\n",
    "\n",
    "# Calculamos el error cuadrático medio con validación cruzada\n",
    "rmse_cv = cross_val_score(ridge_regression, scaled_train, Y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_results_cv.append(np.mean(np.sqrt(np.abs(rmse_cv))))\n",
    "\n",
    "# Calculamos R^2 con validación cruzada\n",
    "r2_cv = cross_val_score(ridge_regression, scaled_train, Y_train, scoring='r2', cv=3)\n",
    "r2_results_cv.append(np.mean(r2_cv))\n",
    "\n",
    "print(f'R Squared: {r_squared_ridge} \\nMean Squared Error:{mse_ridge} \\nRaíz cuadrada de MSE: {np.sqrt(mse_ridge)} \\nR Squared con validación cruzada: {np.mean(np.abs(r2_cv))} \\nRaíz del Mean Squared Error con validación cruzada: {np.mean(np.sqrt(np.abs(rmse_cv)))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.381e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.747e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.888e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor valor de alpha es: 20\n",
      "El valor de los coeficientes para cada una de las variables es: [  -0.         -159.8106934   -89.88238144   -0.           -0.\n",
      "   -0.           -0.            0.          100.05822868 -177.45346975\n",
      "  514.04226239]\n",
      "R Squared: -0.0501299110576654 \n",
      "Mean Squared Error:289500.94618804444 \n",
      "Raíz cuadrada de MSE: 538.0529213637302 \n",
      "R Squared con validación cruzada: 0.05681341902989723 \n",
      "Raíz del Mean Squared Error con validación cruzada: 564.8244416974513\n"
     ]
    }
   ],
   "source": [
    "# LASSO\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "# Valores de alpha\n",
    "parameters = {\"alpha\":[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20,30]}\n",
    "\n",
    "# Grid search para lasso regression\n",
    "lasso_regression = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "lasso_regression.fit(scaled_train, Y_train)\n",
    "print(f\"El mejor valor de alpha es: {lasso_regression.best_params_['alpha']}\")\n",
    "\n",
    "# Entrenamos\n",
    "\n",
    "lasso = Lasso(alpha=lasso_regression.best_params_['alpha'])\n",
    "lasso_regression = lasso.fit(scaled_train, Y_train)\n",
    "\n",
    "print(f\"El valor de los coeficientes para cada una de las variables es: {lasso_regression.coef_}\")\n",
    "# Las columnas son: ['age', 'anaemia', 'diabetes', 'ejection_fraction','high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium','sex', 'smoking', 'time']\n",
    "# En este caso, las caracteristicas mas relevantes son anaemia, diabetes ,sex, smoking y time. \n",
    "# En este caso, los coeficientes pueden ser cero, lo que indica que la variable no es relevante para el modelo. Esto ocurre porque Lasso realiza una regularizacion L1, que \n",
    "# disminuye los coeficientes que son muy grandes, llegando a hacerlos cero si es necesario.\n",
    "\n",
    "# Obtenemos la salida predicha\n",
    "y_pred_lasso = lasso_regression.predict(scaled_test)\n",
    "\n",
    "# Calculamos el error cuadrático medio\n",
    "mse_lasso=metrics.mean_squared_error(Y_test, y_pred_lasso)\n",
    "mse_results.append(mse_lasso)\n",
    "\n",
    "# Calculamos R2\n",
    "r_squared_lasso=metrics.r2_score(Y_test, y_pred_lasso)\n",
    "r2_results.append(r_squared_lasso)\n",
    "\n",
    "# Calculamos el error cuadrático medio con validación cruzada\n",
    "rmse_cv = cross_val_score(lasso_regression, scaled_train, Y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_results_cv.append(np.mean(np.sqrt(np.abs(rmse_cv))))\n",
    "\n",
    "# Calculamos R^2 con validación cruzada\n",
    "r2_cv = cross_val_score(lasso_regression, scaled_train, Y_train, scoring='r2', cv=3)\n",
    "r2_results_cv.append(np.mean(r2_cv))\n",
    "\n",
    "print(f'R Squared: {r_squared_lasso} \\nMean Squared Error:{mse_lasso} \\nRaíz cuadrada de MSE: {np.sqrt(mse_lasso) } \\nR Squared con validación cruzada: {np.mean(np.abs(r2_cv))} \\nRaíz del Mean Squared Error con validación cruzada: {np.mean(np.sqrt(np.abs(rmse_cv)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.936e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.947e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.488e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.930e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.821e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.452e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.912e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.904e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.226e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.838e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.862e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.820e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.807e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.389e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.860e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.648e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.367e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.502e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.606e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.135e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.836e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.808e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.968e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.523e+06, tolerance: 1.247e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e+06, tolerance: 2.233e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.959e+06, tolerance: 2.307e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor valor de alpha es: 1\n",
      "El mejor valor de l1_ratio es: 0.8\n",
      "El valor de los coeficientes para cada una de las variables es: [ -49.10547905 -137.68741614  -83.18424207  -58.7774027   -39.67927452\n",
      "  -31.63002541  -33.52985601   39.34697158   79.64208975 -136.82124022\n",
      "  215.14442802]\n",
      "R Squared: 0.002828509363624887 \n",
      "Mean Squared Error:274901.31174362963 \n",
      "Raíz cuadrada de MSE: 524.3103200811802 \n",
      "R Squared con validación cruzada: 0.02984005705988335 \n",
      "Raíz del Mean Squared Error con validación cruzada: 544.9266806329402\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Elastic net es una combinación de ridge y lasso, además de buscar alpha, también deberemos encontrar la proporcion de ridge y lasso óptima para el modelo\n",
    "# Valores de alpha y l1_ratio\n",
    "parameters = {\"alpha\":[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20,30], \"l1_ratio\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "\n",
    "# Grid search para elastic net\n",
    "elastic_net_regression = GridSearchCV(elastic_net, parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "elastic_net_regression.fit(scaled_train, Y_train)\n",
    "\n",
    "print(f\"El mejor valor de alpha es: {elastic_net_regression.best_params_['alpha']}\")\n",
    "print(f\"El mejor valor de l1_ratio es: {elastic_net_regression.best_params_['l1_ratio']}\") # UN valor de 0.8 indica que lasso tiene mucho más peso que ridge\n",
    "\n",
    "# Entrenamos\n",
    "\n",
    "elastic_net = ElasticNet(alpha=elastic_net_regression.best_params_['alpha'], l1_ratio=elastic_net_regression.best_params_['l1_ratio'])\n",
    "elastic_net_regression = elastic_net.fit(scaled_train, Y_train)\n",
    "\n",
    "print(f\"El valor de los coeficientes para cada una de las variables es: {elastic_net_regression.coef_}\")\n",
    "# Las columnas son: ['age', 'anaemia', 'diabetes', 'ejection_fraction','high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium','sex', 'smoking', 'time']\n",
    "# Las caracteristicas mas relevantes son anaemia, diabetes ,sex, smoking y time, las mismas que para ridge y LASSO. \n",
    "\n",
    "# Obtenemos la salida predicha\n",
    "y_pred_elastic_net = elastic_net_regression.predict(scaled_test)\n",
    "\n",
    "# Calculamos el error cuadrático medio\n",
    "mse_elastic_net=metrics.mean_squared_error(Y_test, y_pred_elastic_net)\n",
    "mse_results.append(mse_elastic_net)\n",
    "\n",
    "# Calculamos R2\n",
    "r_squared_elastic_net=metrics.r2_score(Y_test, y_pred_elastic_net)\n",
    "r2_results.append(r_squared_elastic_net)\n",
    "\n",
    "# Calculamos el error cuadrático medio con validación cruzada\n",
    "rmse_cv = cross_val_score(elastic_net_regression, scaled_train, Y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_results_cv.append(np.mean(np.sqrt(np.abs(rmse_cv))))\n",
    "\n",
    "# Calculamos R^2 con validación cruzada\n",
    "r2_cv = cross_val_score(elastic_net_regression, scaled_train, Y_train, scoring='r2', cv=3)\n",
    "r2_results_cv.append(np.mean(r2_cv))\n",
    "\n",
    "print(f'R Squared: {r_squared_elastic_net} \\nMean Squared Error:{mse_elastic_net} \\nRaíz cuadrada de MSE: {np.sqrt(mse_elastic_net)} \\nR Squared con validación cruzada: {np.mean(np.abs(r2_cv))} \\nRaíz del Mean Squared Error con validación cruzada: {np.mean(np.sqrt(np.abs(rmse_cv)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indique si las figuras de mérito obtenidas en el conjunto de test cambian al\n",
    "cambiar la regularización considerada.\n",
    "\n",
    "Si cambian, en LASSO tenemos el mayor MSE y el menor R squared utilizando la regularización L1, y en Elastic Net tenemos los mejores resultados, ya que combinamos las regularizaciones utilizadas en Ridge y en LASSO para dar lugar a un modelo óptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2 en el conjunto de test</th>\n",
       "      <th>MSE en el conjunto de test</th>\n",
       "      <th>Raíz MSE en el conjunto de test</th>\n",
       "      <th>R2 con validación cruzada</th>\n",
       "      <th>Raíz MSE con validación cruzada</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Regresión lineal</th>\n",
       "      <td>0.036589</td>\n",
       "      <td>2.655941e+05</td>\n",
       "      <td>515.358264</td>\n",
       "      <td>0.182261</td>\n",
       "      <td>594.707928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RL multivariable</th>\n",
       "      <td>0.059778</td>\n",
       "      <td>2.592013e+05</td>\n",
       "      <td>509.118168</td>\n",
       "      <td>0.191725</td>\n",
       "      <td>576.684378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regresión no lineal (polinómica)</th>\n",
       "      <td>-2.875307</td>\n",
       "      <td>1.068349e+06</td>\n",
       "      <td>1033.609650</td>\n",
       "      <td>0.783816</td>\n",
       "      <td>717.403385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regresión no lineal (logartimica)</th>\n",
       "      <td>0.038785</td>\n",
       "      <td>2.649888e+05</td>\n",
       "      <td>514.770666</td>\n",
       "      <td>-0.194969</td>\n",
       "      <td>597.507655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regresión no lineal (exponencial)</th>\n",
       "      <td>0.034505</td>\n",
       "      <td>2.661686e+05</td>\n",
       "      <td>515.915280</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>589.150308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rigde</th>\n",
       "      <td>-0.029485</td>\n",
       "      <td>2.838094e+05</td>\n",
       "      <td>532.737650</td>\n",
       "      <td>0.029309</td>\n",
       "      <td>544.906910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>-0.050130</td>\n",
       "      <td>2.895009e+05</td>\n",
       "      <td>538.052921</td>\n",
       "      <td>-0.056813</td>\n",
       "      <td>564.824442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elastic Net</th>\n",
       "      <td>0.002829</td>\n",
       "      <td>2.749013e+05</td>\n",
       "      <td>524.310320</td>\n",
       "      <td>0.029840</td>\n",
       "      <td>544.926681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   R2 en el conjunto de test  \\\n",
       "Models                                                         \n",
       "Regresión lineal                                    0.036589   \n",
       "RL multivariable                                    0.059778   \n",
       "Regresión no lineal (polinómica)                   -2.875307   \n",
       "Regresión no lineal (logartimica)                   0.038785   \n",
       "Regresión no lineal (exponencial)                   0.034505   \n",
       "Rigde                                              -0.029485   \n",
       "Lasso                                              -0.050130   \n",
       "Elastic Net                                         0.002829   \n",
       "\n",
       "                                   MSE en el conjunto de test  \\\n",
       "Models                                                          \n",
       "Regresión lineal                                 2.655941e+05   \n",
       "RL multivariable                                 2.592013e+05   \n",
       "Regresión no lineal (polinómica)                 1.068349e+06   \n",
       "Regresión no lineal (logartimica)                2.649888e+05   \n",
       "Regresión no lineal (exponencial)                2.661686e+05   \n",
       "Rigde                                            2.838094e+05   \n",
       "Lasso                                            2.895009e+05   \n",
       "Elastic Net                                      2.749013e+05   \n",
       "\n",
       "                                   Raíz MSE en el conjunto de test  \\\n",
       "Models                                                               \n",
       "Regresión lineal                                        515.358264   \n",
       "RL multivariable                                        509.118168   \n",
       "Regresión no lineal (polinómica)                       1033.609650   \n",
       "Regresión no lineal (logartimica)                       514.770666   \n",
       "Regresión no lineal (exponencial)                       515.915280   \n",
       "Rigde                                                   532.737650   \n",
       "Lasso                                                   538.052921   \n",
       "Elastic Net                                             524.310320   \n",
       "\n",
       "                                   R2 con validación cruzada  \\\n",
       "Models                                                         \n",
       "Regresión lineal                                    0.182261   \n",
       "RL multivariable                                    0.191725   \n",
       "Regresión no lineal (polinómica)                    0.783816   \n",
       "Regresión no lineal (logartimica)                  -0.194969   \n",
       "Regresión no lineal (exponencial)                  -0.156858   \n",
       "Rigde                                               0.029309   \n",
       "Lasso                                              -0.056813   \n",
       "Elastic Net                                         0.029840   \n",
       "\n",
       "                                   Raíz MSE con validación cruzada  \n",
       "Models                                                              \n",
       "Regresión lineal                                        594.707928  \n",
       "RL multivariable                                        576.684378  \n",
       "Regresión no lineal (polinómica)                        717.403385  \n",
       "Regresión no lineal (logartimica)                       597.507655  \n",
       "Regresión no lineal (exponencial)                       589.150308  \n",
       "Rigde                                                   544.906910  \n",
       "Lasso                                                   564.824442  \n",
       "Elastic Net                                             544.926681  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results[\"R2 en el conjunto de test\"] = r2_results\n",
    "results[\"MSE en el conjunto de test\"] = mse_results\n",
    "results[\"Raíz MSE en el conjunto de test\"] = np.sqrt(mse_results)\n",
    "results[\"R2 con validación cruzada\"] = r2_results_cv\n",
    "results[\"Raíz MSE con validación cruzada\"] = rmse_results_cv\n",
    "\n",
    "#results\n",
    "results[\"Models\"] = [\"Regresión lineal\", \"RL multivariable\", \"Regresión no lineal (polinómica)\", \"Regresión no lineal (logartimica)\",\n",
    "\"Regresión no lineal (exponencial)\" , \"Rigde\", \"Lasso\", \"Elastic Net\"]\n",
    "results.set_index(\"Models\", inplace = True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los resultados podemos conluir que lo mejor es utilizar un modelo de regresión lineal multivariable ya que nos roporciona el menor error en el conjunto de test así como el mayor valor de R squared. Este resultado se puede deber a la dificultad de predecir los valroes de la CPK con tan pocos datos y variables tan poco correlacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor del intercepto: 230.7369753713326\n",
      "Valor de los coeficientes: [101.73127348 461.94619981 -21.50082113]\n",
      "R Squared: -0.10525635008760847 \n",
      "Mean Squared Error:304698.2623401693 \n",
      "Raíz cuadrada de MSE: 551.9948028198901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# A continuacion, vamos a realizar una predicción con el modelo de regresion lineal mutivariable usando una partición diferente\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_input, data_output, test_size=0.3, random_state = 89318)\n",
    "\n",
    "# Normalizamos los datos del conjunto train\n",
    "\n",
    "x_res_train = x_train.copy()\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "data_minmax = scaler.fit_transform(x_res_train)\n",
    "\n",
    "scaled_train = pd.DataFrame(data_minmax, columns=x_res_train.columns)\n",
    "\n",
    "# Normalizamos el conjunto de test\n",
    "\n",
    "x_res_test = x_test.copy()\n",
    "\n",
    "data_minmax = scaler.transform(x_res_test)\n",
    "\n",
    "scaled_test = pd.DataFrame(data_minmax, columns=x_res_test.columns)\n",
    "\n",
    "# Regresión lineal simple multiple\n",
    "regressor_ = LinearRegression()\n",
    "\n",
    "# Entrenamos el modelo utilizando los datos de train\n",
    "col = [\"time\", \"age\", \"serum_creatinine\"] \n",
    "regressor_ = regressor_.fit(scaled_train[col], Y_train)\n",
    "\n",
    "# Mostramos el valor del intercepto (wo)\n",
    "print(f\"Valor del intercepto: {regressor_.intercept_}\")\n",
    "\n",
    "# Mostramos el valor de los coeficientes\n",
    "print(f\"Valor de los coeficientes: {regressor_.coef_}\") \n",
    "\n",
    "# Obtenemos el valor predicho para el conjunto de test\n",
    "y_pred = regressor_.predict(np.array(scaled_test[col]))\n",
    "\n",
    "#  Calculamos el error cuadrático medio\n",
    "mse_m=metrics.mean_squared_error(Y_test, y_pred)\n",
    "mse_results.append(mse_m)\n",
    "\n",
    "# Calculamos R^2\n",
    "r_squared_m=metrics.r2_score(Y_test, y_pred)\n",
    "r2_results.append(r_squared_m)\n",
    "\n",
    "print(f'R Squared: {r_squared_m} \\nMean Squared Error:{mse_m} \\nRaíz cuadrada de MSE: {np.sqrt(mse_m)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared: -0.187583370602173 \n",
      "Mean Squared Error:327394.2641251334 \n",
      "Raíz cuadrada de MSE: 572.1837677924229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# En este caso, vamos a usar el predictor que hemos entrenado al principio con la particion que acabamos de hacer\n",
    "\n",
    "y_pred = regressor.predict(np.array(scaled_test[col]))\n",
    "\n",
    "#  Calculamos el error cuadrático medio\n",
    "mse_m=metrics.mean_squared_error(Y_test, y_pred)\n",
    "mse_results.append(mse_m)\n",
    "\n",
    "# Calculamos R^2\n",
    "r_squared_m=metrics.r2_score(Y_test, y_pred)\n",
    "r2_results.append(r_squared_m)\n",
    "\n",
    "print(f'R Squared: {r_squared_m} \\nMean Squared Error:{mse_m} \\nRaíz cuadrada de MSE: {np.sqrt(mse_m)}')\n",
    "\n",
    "# Podemos comprobar que el resultado es peor ya que hemos entrenado el regresor con un conjunto de datos que no es el mismo que el que estamos usando para predecir, por esto \n",
    "# el error es mayor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos y hacemos la partición\n",
    "\n",
    "data_c = data_input.copy()\n",
    "data_c[\"creatinine_phosphokinase\"] = data_output\n",
    "data_c_output = data[\"DEATH_EVENT\"]\n",
    "\n",
    "X_train_c, X_test_c, Y_train_c, Y_test_c = train_test_split(data_c, data_c_output, test_size=0.3, random_state = 777)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.426377</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.433949</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.392704</td>\n",
       "      <td>0.301510</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.387736</td>\n",
       "      <td>0.151371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.233717</td>\n",
       "      <td>0.500783</td>\n",
       "      <td>0.496461</td>\n",
       "      <td>0.244455</td>\n",
       "      <td>0.500783</td>\n",
       "      <td>0.164162</td>\n",
       "      <td>0.214593</td>\n",
       "      <td>0.194123</td>\n",
       "      <td>0.489706</td>\n",
       "      <td>0.458861</td>\n",
       "      <td>0.293012</td>\n",
       "      <td>0.210482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296739</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101887</td>\n",
       "      <td>0.019476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.387882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313208</td>\n",
       "      <td>0.057881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.441848</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.194758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age    anaemia   diabetes  ejection_fraction  \\\n",
       "count  88.000000  88.000000  88.000000          88.000000   \n",
       "mean    0.426377   0.454545   0.420455           0.433949   \n",
       "std     0.233717   0.500783   0.496461           0.244455   \n",
       "min     0.000000   0.000000   0.000000           0.000000   \n",
       "25%     0.272727   0.000000   0.000000           0.270833   \n",
       "50%     0.387882   0.000000   0.000000           0.437500   \n",
       "75%     0.545455   1.000000   1.000000           0.583333   \n",
       "max     1.000000   1.000000   1.000000           1.000000   \n",
       "\n",
       "       high_blood_pressure  platelets  serum_creatinine  serum_sodium  \\\n",
       "count            88.000000  88.000000         88.000000     88.000000   \n",
       "mean              0.454545   0.392704          0.301510      0.597403   \n",
       "std               0.500783   0.164162          0.214593      0.194123   \n",
       "min               0.000000   0.000000          0.000000      0.000000   \n",
       "25%               0.000000   0.296739          0.190476      0.476190   \n",
       "50%               0.000000   0.391304          0.238095      0.619048   \n",
       "75%               1.000000   0.441848          0.345238      0.714286   \n",
       "max               1.000000   1.000000          1.000000      1.000000   \n",
       "\n",
       "             sex    smoking       time  creatinine_phosphokinase  \n",
       "count  88.000000  88.000000  88.000000                 88.000000  \n",
       "mean    0.613636   0.295455   0.387736                  0.151371  \n",
       "std     0.489706   0.458861   0.293012                  0.210482  \n",
       "min     0.000000   0.000000   0.000000                  0.000000  \n",
       "25%     0.000000   0.000000   0.101887                  0.019476  \n",
       "50%     1.000000   0.000000   0.313208                  0.057881  \n",
       "75%     1.000000   1.000000   0.679245                  0.194758  \n",
       "max     1.000000   1.000000   1.000000                  1.000000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizamos el conjunto de train\n",
    "X_res_train_c = X_train_c.copy()\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Todos los valores están en el rango [0,1]\n",
    "data_minmax_c = scaler.fit_transform(X_res_train_c)\n",
    "\n",
    "scaled_train_c = pd.DataFrame(data_minmax_c, columns=X_res_train_c.columns)\n",
    "scaled_train_c.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.417544</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.398026</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.411654</td>\n",
       "      <td>0.322989</td>\n",
       "      <td>0.550937</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.354121</td>\n",
       "      <td>0.153268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.243465</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>0.239493</td>\n",
       "      <td>0.503897</td>\n",
       "      <td>0.215505</td>\n",
       "      <td>0.247220</td>\n",
       "      <td>0.157426</td>\n",
       "      <td>0.471069</td>\n",
       "      <td>0.446258</td>\n",
       "      <td>0.291629</td>\n",
       "      <td>0.193703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.056522</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007547</td>\n",
       "      <td>-0.008737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288043</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100943</td>\n",
       "      <td>0.028668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406911</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.094467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.595455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529891</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.583962</td>\n",
       "      <td>0.194758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898113</td>\n",
       "      <td>0.900983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age    anaemia   diabetes  ejection_fraction  \\\n",
       "count  38.000000  38.000000  38.000000          38.000000   \n",
       "mean    0.417544   0.500000   0.500000           0.398026   \n",
       "std     0.243465   0.506712   0.506712           0.239493   \n",
       "min     0.000000   0.000000   0.000000          -0.041667   \n",
       "25%     0.181818   0.000000   0.000000           0.270833   \n",
       "50%     0.436364   0.500000   0.500000           0.375000   \n",
       "75%     0.595455   1.000000   1.000000           0.479167   \n",
       "max     1.000000   1.000000   1.000000           0.895833   \n",
       "\n",
       "       high_blood_pressure  platelets  serum_creatinine  serum_sodium  \\\n",
       "count            38.000000  38.000000         38.000000     38.000000   \n",
       "mean              0.447368   0.411654          0.322989      0.550937   \n",
       "std               0.503897   0.215505          0.247220      0.157426   \n",
       "min               0.000000  -0.056522         -0.047619      0.190476   \n",
       "25%               0.000000   0.288043          0.190476      0.440476   \n",
       "50%               0.000000   0.406911          0.257143      0.571429   \n",
       "75%               1.000000   0.529891          0.404762      0.666667   \n",
       "max               1.000000   0.843478          1.142857      0.857143   \n",
       "\n",
       "             sex    smoking       time  creatinine_phosphokinase  \n",
       "count  38.000000  38.000000  38.000000                 38.000000  \n",
       "mean    0.684211   0.263158   0.354121                  0.153268  \n",
       "std     0.471069   0.446258   0.291629                  0.193703  \n",
       "min     0.000000   0.000000  -0.007547                 -0.008737  \n",
       "25%     0.000000   0.000000   0.100943                  0.028668  \n",
       "50%     1.000000   0.000000   0.273585                  0.094467  \n",
       "75%     1.000000   0.750000   0.583962                  0.194758  \n",
       "max     1.000000   1.000000   0.898113                  0.900983  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizamos el conjunto de test\n",
    "\n",
    "X_res_test_c = X_test_c.copy()\n",
    "\n",
    "data_minmax_c = scaler.transform(X_res_test_c)\n",
    "\n",
    "scaled_test_c = pd.DataFrame(data_minmax_c, columns=X_res_test_c.columns)\n",
    "scaled_test_c.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               age   anaemia  diabetes  ejection_fraction  \\\n",
      "age                       1.000000 -0.022076 -0.046849           0.161716   \n",
      "anaemia                  -0.022076  1.000000 -0.130291           0.093537   \n",
      "diabetes                 -0.046849 -0.130291  1.000000          -0.088185   \n",
      "ejection_fraction         0.161716  0.093537 -0.088185           1.000000   \n",
      "high_blood_pressure       0.017207 -0.100000  0.147103          -0.117722   \n",
      "platelets                -0.044028 -0.208629  0.075807           0.026037   \n",
      "serum_creatinine          0.169503  0.024839 -0.032745          -0.279697   \n",
      "serum_sodium             -0.084807  0.017915 -0.069185           0.233609   \n",
      "sex                       0.278750 -0.072436 -0.127866          -0.135614   \n",
      "smoking                   0.283108 -0.140967 -0.097472          -0.127167   \n",
      "time                     -0.139400 -0.070352  0.054342          -0.023411   \n",
      "creatinine_phosphokinase -0.127952 -0.202837 -0.112569          -0.110281   \n",
      "DEATH_EVENT               0.002212 -0.052535  0.130803          -0.056489   \n",
      "\n",
      "                          high_blood_pressure  platelets  serum_creatinine  \\\n",
      "age                                  0.017207  -0.044028          0.169503   \n",
      "anaemia                             -0.100000  -0.208629          0.024839   \n",
      "diabetes                             0.147103   0.075807         -0.032745   \n",
      "ejection_fraction                   -0.117722   0.026037         -0.279697   \n",
      "high_blood_pressure                  1.000000   0.139025          0.007013   \n",
      "platelets                            0.139025   1.000000         -0.062893   \n",
      "serum_creatinine                     0.007013  -0.062893          1.000000   \n",
      "serum_sodium                        -0.128474   0.033483         -0.234205   \n",
      "sex                                 -0.119306  -0.154760          0.040276   \n",
      "smoking                             -0.090947  -0.019341          0.016236   \n",
      "time                                -0.135679   0.043744         -0.132289   \n",
      "creatinine_phosphokinase            -0.076881  -0.072351         -0.086911   \n",
      "DEATH_EVENT                          0.213113  -0.031113          0.164304   \n",
      "\n",
      "                          serum_sodium       sex   smoking      time  \\\n",
      "age                          -0.084807  0.278750  0.283108 -0.139400   \n",
      "anaemia                       0.017915 -0.072436 -0.140967 -0.070352   \n",
      "diabetes                     -0.069185 -0.127866 -0.097472  0.054342   \n",
      "ejection_fraction             0.233609 -0.135614 -0.127167 -0.023411   \n",
      "high_blood_pressure          -0.128474 -0.119306 -0.090947 -0.135679   \n",
      "platelets                     0.033483 -0.154760 -0.019341  0.043744   \n",
      "serum_creatinine             -0.234205  0.040276  0.016236 -0.132289   \n",
      "serum_sodium                  1.000000 -0.037163  0.029606  0.100984   \n",
      "sex                          -0.037163  1.000000  0.462694 -0.091441   \n",
      "smoking                       0.029606  0.462694  1.000000 -0.060165   \n",
      "time                          0.100984 -0.091441 -0.060165  1.000000   \n",
      "creatinine_phosphokinase      0.102338  0.087107 -0.166506  0.386178   \n",
      "DEATH_EVENT                  -0.161337 -0.042596 -0.048602  0.017091   \n",
      "\n",
      "                          creatinine_phosphokinase  DEATH_EVENT  \n",
      "age                                      -0.127952     0.002212  \n",
      "anaemia                                  -0.202837    -0.052535  \n",
      "diabetes                                 -0.112569     0.130803  \n",
      "ejection_fraction                        -0.110281    -0.056489  \n",
      "high_blood_pressure                      -0.076881     0.213113  \n",
      "platelets                                -0.072351    -0.031113  \n",
      "serum_creatinine                         -0.086911     0.164304  \n",
      "serum_sodium                              0.102338    -0.161337  \n",
      "sex                                       0.087107    -0.042596  \n",
      "smoking                                  -0.166506    -0.048602  \n",
      "time                                      0.386178     0.017091  \n",
      "creatinine_phosphokinase                  1.000000    -0.088059  \n",
      "DEATH_EVENT                              -0.088059     1.000000  \n",
      "Caracteristicas seleccionadas: Index(['ejection_fraction', 'serum_creatinine', 'time'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Primero vamos a observar la matriz de correlacion para saber que variables estan mas correladas con la variable dependiente\n",
    "\n",
    "datos_a_correlar = scaled_train_c.copy()\n",
    "datos_a_correlar[\"DEATH_EVENT\"] = Y_train_c\n",
    "\n",
    "# Mostramos la matriz de correlacion para saber que datos están mas correlados con la variable dependiente\n",
    "correlacion = datos_a_correlar.corr()\n",
    "print(correlacion)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "selectKBest = SelectKBest(chi2, k=3)\n",
    "selectKBest.fit(scaled_train_c, Y_train_c)\n",
    "indices_seleccionados = selectKBest.get_support()\n",
    "caracteristicas = scaled_train_c.columns\n",
    "print(f\"Caracteristicas seleccionadas: {caracteristicas[indices_seleccionados]}\")\n",
    "\n",
    "#Utilizando este metodo, podemos ver que variables son las que han obtenido scores y pvalues mas relevantes, y por lo tanto las que se han elegido\n",
    "#utilizando SelectKBest. Esta funcion solo tiene en cuenta la relacion de las variables con la variable dependiente, no tiene en cuenta la relacion entre las distintas variables independientes\n",
    "\n",
    "#print(selectKBest.scores_)\n",
    "#print(selectKBest.pvalues_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor del intercepto: 0.5846960614153359\n",
      "Valor del coeficiente B1: -2.034245520030937\n",
      "Accuracy del modelo: 0.79\n",
      "Precisión del modelo: 0.89\n",
      "Sensibilidad del modelo: 0.74\n",
      "F1 score del modelo: 0.81\n",
      "Accuracy del modelo con validación cruzada: 0.76\n",
      "Precisión del modelo con validación cruzada: 0.76\n",
      "Sensibilidad del modelo con validación cruzada: 0.70\n",
      "F1 score del modelo con validación cruzada: 0.72\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18a8f0e2e80>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basándonos en los datos obtenidos en la matriz de correlacion, en los resultados obtenidos en SelectKBest y en varias pruebas que hemos realizado, \n",
    "# decidimos utilzar time como variable independiente\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "acc_results_c=[] # accuracy\n",
    "prec_results_c=[] # precision\n",
    "recall_results_c=[] # recall\n",
    "f1_results_c=[] # f1 score\n",
    "acc_results_c_cv = [] # accuracy con validacion cruzada\n",
    "prec_results_c_cv = [] # precision con validacion cruzada\n",
    "recall_results_c_cv = [] # recall con validacion cruzada\n",
    "f1_results_c_cv = [] # f1 score con validacion cruzada\n",
    "\n",
    "# Regresión logistica simple\n",
    "regressor = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo utilizando los datos de train\n",
    "regressor = regressor.fit(np.array(scaled_train_c['time']).reshape(-1, 1), Y_train_c)\n",
    "\n",
    "# Mostramos el valor del intercepto (Bo)\n",
    "B0 = regressor.intercept_\n",
    "print(f\"Valor del intercepto: {B0[0]}\")\n",
    "\n",
    "# Mostramos el valor de los coeficientes (B1)\n",
    "B1 = regressor.coef_ # Si B1 es negativo, la probabilidad de que el paciente muera aumenta a medida que disminuye el valor de time\n",
    "print(f\"Valor del coeficiente B1: {B1[0][0]}\")\n",
    "\n",
    "# Obtenemos el valor predicho para el conjunto de test\n",
    "y_pred = regressor.predict(np.array(scaled_test_c['time']).reshape(-1,1))\n",
    "\n",
    "#Calculamos el accuracy\n",
    "accuracy = accuracy_score(Y_test_c, y_pred)\n",
    "print(f'Accuracy del modelo: {accuracy:.2f}')\n",
    "acc_results_c.append(accuracy)\n",
    "\n",
    "#Calculamos la precisión\n",
    "precision = metrics.precision_score(Y_test_c, y_pred)\n",
    "print(f'Precisión del modelo: {precision:.2f}')\n",
    "prec_results_c.append(precision)\n",
    "\n",
    "#Calculamos la sensibilidad\n",
    "recall = metrics.recall_score(Y_test_c, y_pred)\n",
    "print(f'Sensibilidad del modelo: {recall:.2f}')\n",
    "recall_results_c.append(recall)\n",
    "# En nuestro modelo, estamos tratando de predecir si un paciente va a tener un fallo cardiaco que le provoque la muerte, por lo que la métrica más importante \n",
    "# será la sensibilidad, que mide la capacidad del modelo para predecir correctamente los casos positivos. El resto de métricas pasarán a un segundo plano\n",
    "\n",
    "#Calculamos el f1 score\n",
    "f1 = metrics.f1_score(Y_test_c, y_pred)\n",
    "print(f'F1 score del modelo: {f1:.2f}')\n",
    "f1_results_c.append(f1)\n",
    "\n",
    "# Calculamos el accuracy con validación cruzada\n",
    "acc_cv = cross_val_score(regressor, np.array(scaled_train_c['time']).reshape(-1, 1), Y_train_c, scoring='accuracy', cv=3)\n",
    "acc_results_c_cv.append(np.mean(acc_cv))\n",
    "print(f'Accuracy del modelo con validación cruzada: {np.mean(acc_cv):.2f}')\n",
    "\n",
    "# Calculamos la precisión con validación cruzada\n",
    "prec_cv = cross_val_score(regressor, np.array(scaled_train_c['time']).reshape(-1, 1), Y_train_c, scoring='precision', cv=3)\n",
    "prec_results_c_cv.append(np.mean(prec_cv))\n",
    "print(f'Precisión del modelo con validación cruzada: {np.mean(prec_cv):.2f}')\n",
    "\n",
    "# Calculamos la sensibilidad con validación cruzada\n",
    "recall_cv = cross_val_score(regressor, np.array(scaled_train_c['time']).reshape(-1, 1), Y_train_c, scoring='recall', cv=3)\n",
    "recall_results_c_cv.append(np.mean(recall_cv))\n",
    "print(f'Sensibilidad del modelo con validación cruzada: {np.mean(recall_cv):.2f}')\n",
    "\n",
    "# Calculamos el f1 score con validación cruzada\n",
    "f1_cv = cross_val_score(regressor, np.array(scaled_train_c['time']).reshape(-1, 1), Y_train_c, scoring='f1', cv=3)\n",
    "f1_results_c_cv.append(np.mean(f1_cv))\n",
    "print(f'F1 score del modelo con validación cruzada: {np.mean(f1_cv):.2f}')\n",
    "\n",
    "# Creamos la curva de regresión\n",
    "X = np.linspace(0,1,100)\n",
    "Y = 1/(1+np.exp(-(B0[0] + B1[0][0]*X)))\n",
    "\n",
    "plt.scatter(scaled_train_c[\"time\"], Y_train_c, color='blue', label='Datos de Ejemplo')\n",
    "plt.plot(X, Y, color='red', label='Regresión Logística') # TODO: Mandar este codigo a cristinna\n",
    "plt.xlabel('Variable Independiente')\n",
    "plt.ylabel('Probabilidad de Clase 1')\n",
    "plt.title('Regresión Logística en Python')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#También podemos observar la matriz de confusión\n",
    "# El objetivo de nuestro modelo, es predecir la muerte de un paciente, por lo tanto, lo que mas nos interesa es que los casos de muerte se predigan correctamente, \n",
    "# por lo tanto, nos interesa que la sensibilidad sea lo mas alta posible\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(Y_test_c, y_pred), display_labels=[\"No muerte\", \"Muerte\"]).plot()\n",
    "# Observandola, podemos apreciar que casi todos los casos de No Muerte, son predichos correctamente, mientras que en los casos de Muerte, \n",
    "# se predice correctamente el 75% de los casos (aproximadamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuestiones \n",
    "\n",
    "¿Cuál es la variable dependiente que se podría considerar para abordar un problema\n",
    "de clasificación?\n",
    "Se podría considerar cualquier variable binaria o categórica.\n",
    "\n",
    "¿Qué variable es la que permite una mejor estimación de la variable dependiente?\n",
    "En nuestro caso, la variable que mejor predice los resultados es la variable time. Para hallar que variables son las que consiguen un mejor resultado, nos hemos basado en los resultados obtenidos utilizando selectKBest y en los resultados de la matriz de correlación. Una vez hemos visto qeu variables son las más significantes a la hora de predecir, hemos visto cuál de ellas era la que mejor sensibilidad aportaba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística multivariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor del intercepto: 0.7439005153379203\n",
      "Valor de los coeficientes: [[ 1.50316134 -1.4271214  -2.01941889]]\n",
      "Accuracy del modelo: 0.8157894736842105\n",
      "Precisión del modelo: 0.9444444444444444\n",
      "Sensibilidad del modelo: 0.7391304347826086\n",
      "F1 score del modelo: 0.8292682926829269\n",
      "Accuracy del modelo con validación cruzada: 0.7735632183908047\n",
      "Precisión del modelo con validación cruzada: 0.832977207977208\n",
      "Sensibilidad del modelo con validación cruzada: 0.6282051282051282\n",
      "F1 score del modelo con validación cruzada: 0.707172054998142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18a8f141e20>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Regresión logistico simple multiple\n",
    "regressor = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo utilizando los datos de train\n",
    "col = [\"serum_creatinine\", \"ejection_fraction\", \"time\"]\n",
    "# Cuantas más variables usemos, más información se tendrá en cuenta a la hora de predecir la salida del modelo, pero también podemos caer en overfitting. Además,\n",
    "# es importante no escoger variables que esten demasiado correladas entre si, ya que podríamos tener problemas de multicolinealidad.\n",
    "regressor = regressor.fit(scaled_train_c[col], Y_train_c)\n",
    "\n",
    "# Mostramos el valor del intercepto (wo)\n",
    "print(f\"Valor del intercepto: {regressor.intercept_[0]}\")\n",
    "\n",
    "# Mostramos el valor de los coeficientes (w1)\n",
    "print(f\"Valor de los coeficientes: {regressor.coef_}\") # Del resultado podemos decir que a medida que aumenta el valor de serum, aumenta la probabilidad de que el paciente muera, \n",
    "# y a medida que aumenta el valor de ejection_fraction y el de time, disminuye la probabilidad de que el paciente muera \n",
    "\n",
    "# Obtenemos el valor predicho para el conjunto de test\n",
    "y_pred = regressor.predict(np.array(scaled_test_c[col]))\n",
    "\n",
    "#Calculamos el accuracy\n",
    "accuracy_m = accuracy_score(Y_test_c, y_pred)\n",
    "print(f'Accuracy del modelo: {accuracy_m}')\n",
    "acc_results_c.append(accuracy_m)\n",
    "\n",
    "#Calculamos la precisión\n",
    "precision_m = metrics.precision_score(Y_test_c, y_pred)\n",
    "print(f'Precisión del modelo: {precision_m}')\n",
    "prec_results_c.append(precision_m)\n",
    "\n",
    "#Calculamos el recall\n",
    "recall_m = metrics.recall_score(Y_test_c, y_pred)\n",
    "print(f'Sensibilidad del modelo: {recall_m}')\n",
    "recall_results_c.append(recall_m)\n",
    "\n",
    "#Calculamos el f1 score\n",
    "f1_m = metrics.f1_score(Y_test_c, y_pred)\n",
    "print(f'F1 score del modelo: {f1_m}')\n",
    "f1_results_c.append(f1_m)\n",
    "\n",
    "# Calculamos el accuracy con validación cruzada\n",
    "acc_cv = cross_val_score(regressor, scaled_train_c[col], Y_train_c, scoring='accuracy', cv=3)\n",
    "acc_results_c_cv.append(np.mean(acc_cv))\n",
    "print(f'Accuracy del modelo con validación cruzada: {np.mean(acc_cv)}')\n",
    "\n",
    "# Calculamos la precisión con validación cruzada\n",
    "prec_cv = cross_val_score(regressor, scaled_train_c[col], Y_train_c, scoring='precision', cv=3)\n",
    "prec_results_c_cv.append(np.mean(prec_cv))\n",
    "print(f'Precisión del modelo con validación cruzada: {np.mean(prec_cv)}')\n",
    "\n",
    "# Calculamos la sensibilidad con validación cruzada\n",
    "recall_cv = cross_val_score(regressor, scaled_train_c[col], Y_train_c, scoring='recall', cv=3)\n",
    "recall_results_c_cv.append(np.mean(recall_cv))\n",
    "print(f'Sensibilidad del modelo con validación cruzada: {np.mean(recall_cv)}')\n",
    "\n",
    "# Calculamos el f1 score con validación cruzada\n",
    "f1_cv = cross_val_score(regressor, scaled_train_c[col], Y_train_c, scoring='f1', cv=3)\n",
    "f1_results_c_cv.append(np.mean(f1_cv))\n",
    "print(f'F1 score del modelo con validación cruzada: {np.mean(f1_cv)}')\n",
    "\n",
    "# Podemos observar la matriz de confusión\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(Y_test_c, y_pred), display_labels=[\"No muerte\", \"Muerte\"]).plot()\n",
    "# Observandola, podemos apreciar que la mayoría de los casos de No Muerte, son predichos correctamente, mientras que en los casos de Muerte, \n",
    "# se predice correctamente en casi todos los casos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor valor de alpha es: 30\n",
      "El valor de los coeficientes para cada una de las variables es: [[ 0.05281118 -0.0461924  -0.02574795 -0.18352062 -0.01777748 -0.0110546\n",
      "   0.1930172  -0.09284928  0.11364166  0.01108874 -0.28942297 -0.00699363]]\n",
      "Accuracy del modelo: 0.631578947368421\n",
      "Precisión del modelo: 0.9090909090909091\n",
      "Sensibilidad del modelo: 0.43478260869565216\n",
      "F1 score del modelo: 0.5882352941176471\n",
      "Accuracy del modelo con validación cruzada: 0.6938697318007662\n",
      "Precisión del modelo con validación cruzada: 0.8055555555555555\n",
      "Sensibilidad del modelo con validación cruzada: 0.4249084249084249\n",
      "F1 score del modelo con validación cruzada: 0.5455283562700443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18a8cc6eeb0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ridge\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge = RidgeClassifier()\n",
    "\n",
    "# Valores para alpha\n",
    "parameters = {\"alpha\":[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20,30]}\n",
    "# alpha es el parametro de regularizacion, cuanto mas grande sea, mas penaliza los coeficientes mas grandes, cogemos valores extremos para compararlos\n",
    "\n",
    "# Seleccionamos el mejor valor de alpha\n",
    "ridge_regression = GridSearchCV(ridge, parameters, scoring='accuracy', cv=3) # En este caso usamos scoring=accuracy porque estamos en un problema de clasificación y no de regresión\n",
    "ridge_regression.fit(scaled_train_c, Y_train_c)\n",
    "print(f\"El mejor valor de alpha es: {ridge_regression.best_params_['alpha']}\")\n",
    "# Como ya sabemos el mejor valor de alpha, creamos el modelo con ese valor\n",
    "\n",
    "# Entrenamos\n",
    "\n",
    "ridge = RidgeClassifier(alpha=ridge_regression.best_params_['alpha'])\n",
    "ridge_regression = ridge.fit(scaled_train_c, Y_train_c)\n",
    "\n",
    "print(f\"El valor de los coeficientes para cada una de las variables es: {ridge_regression.coef_}\")\n",
    "# Las columnas son: ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', 'ejection_fraction','high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium','sex', 'smoking', 'time']\n",
    "# Las caracteristicas mas relevantes según ridge son diabetes, smoking y platelets\n",
    "\n",
    "# Se obtiene la salida predicha\n",
    "y_pred_ridge = ridge_regression.predict(scaled_test_c)\n",
    "\n",
    "# Calculamos la exactitud\n",
    "accuracy_r = accuracy_score(Y_test_c, y_pred_ridge)\n",
    "print(f'Accuracy del modelo: {accuracy_r}')\n",
    "acc_results_c.append(accuracy_r)\n",
    "\n",
    "# Calculamos la precisión\n",
    "precision_r = metrics.precision_score(Y_test_c, y_pred_ridge)\n",
    "print(f'Precisión del modelo: {precision_r}')\n",
    "prec_results_c.append(precision_r)\n",
    "\n",
    "# Calculamos el recall\n",
    "recall_r = metrics.recall_score(Y_test_c, y_pred_ridge)\n",
    "print(f'Sensibilidad del modelo: {recall_r}')\n",
    "recall_results_c.append(recall_r)\n",
    "\n",
    "# Calculamos el f1 score\n",
    "f1_r = metrics.f1_score(Y_test_c, y_pred_ridge)\n",
    "print(f'F1 score del modelo: {f1_r}')\n",
    "f1_results_c.append(f1_r)\n",
    "\n",
    "# Calculamos el accuracy con validación cruzada\n",
    "acc_cv = cross_val_score(ridge_regression, scaled_train_c, Y_train_c, scoring='accuracy', cv=3)\n",
    "acc_results_c_cv.append(np.mean(acc_cv))\n",
    "print(f'Accuracy del modelo con validación cruzada: {np.mean(acc_cv)}')\n",
    "\n",
    "# Calculamos la precisión con validación cruzada\n",
    "prec_cv = cross_val_score(ridge_regression, scaled_train_c, Y_train_c, scoring='precision', cv=3)\n",
    "prec_results_c_cv.append(np.mean(prec_cv))\n",
    "print(f'Precisión del modelo con validación cruzada: {np.mean(prec_cv)}')\n",
    "\n",
    "# Calculamos la sensibilidad con validación cruzada\n",
    "recall_cv = cross_val_score(ridge_regression, scaled_train_c, Y_train_c, scoring='recall', cv=3)\n",
    "recall_results_c_cv.append(np.mean(recall_cv))\n",
    "print(f'Sensibilidad del modelo con validación cruzada: {np.mean(recall_cv)}')\n",
    "\n",
    "# Calculamos el f1 score con validación cruzada\n",
    "f1_cv = cross_val_score(ridge_regression, scaled_train_c, Y_train_c, scoring='f1', cv=3)\n",
    "f1_results_c_cv.append(np.mean(f1_cv))\n",
    "print(f'F1 score del modelo con validación cruzada: {np.mean(f1_cv)}')\n",
    "\n",
    "#También podemos observar la matriz de confusión\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(Y_test_c, y_pred_ridge), display_labels=[\"No muerte\", \"Muerte\"]).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor valor de C es: 1\n",
      "El valor de los coeficientes para cada una de las variables es: [[ 0.          0.          0.         -1.1478762   0.          0.\n",
      "   2.64895143  0.          0.47078567  0.         -2.38691269  0.        ]]\n",
      "Accuracy del modelo: 0.8157894736842105\n",
      "Precisión del modelo: 0.9\n",
      "Sensibilidad del modelo: 0.782608695652174\n",
      "F1 score del modelo: 0.8372093023255814\n",
      "Accuracy del modelo con validación cruzada: 0.7275862068965516\n",
      "Precisión del modelo con validación cruzada: 0.7191951566951568\n",
      "Sensibilidad del modelo con validación cruzada: 0.6758241758241758\n",
      "F1 score del modelo con validación cruzada: 0.6872169975618251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18a8f1411f0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LASSO\n",
    "\n",
    "lasso = LogisticRegression(penalty=\"l1\", solver='liblinear')\n",
    "#Como el modelo LASSO no es el óptimo para los problemas de clasificación, se utiliza la regresión logística con el parámetro penalty=\"l1\", este parametro indica \n",
    "# el tipo de penalización que se va a utilizar a la hora de calcular la función de coste, en este caso, l1 es la penalización que se aplica en LASSO\n",
    "# También es necesario cambiar el solver del método para que funcione con nuestra penalización. Entre los posibles (liblinear y saga), nos quedamos con liblinear ya que es\n",
    "# el que mejores resultados da en los casos en los que se tienen pocos datos\n",
    "\n",
    "# Valores de C. C es el inverso de alpha, como LogisticRegression tiene C en lugar de alpha, es necesario encontrar el valor óptimo de C en lugar del de alpha\n",
    "parameters = {\"C\":[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20,30]}\n",
    "\n",
    "\n",
    "# Grid search para lasso regression\n",
    "lasso_regression = GridSearchCV(lasso, parameters, scoring='accuracy', cv=3)\n",
    "lasso_regression.fit(scaled_train_c, Y_train_c)\n",
    "print(f\"El mejor valor de C es: {lasso_regression.best_params_['C']}\")\n",
    "\n",
    "# Entrenamos con el mejor C\n",
    "\n",
    "lasso = LogisticRegression(penalty = \"l1\", solver = \"liblinear\", C=lasso_regression.best_params_['C'])\n",
    "lasso_regression = lasso.fit(scaled_train_c, Y_train_c)\n",
    "\n",
    "print(f\"El valor de los coeficientes para cada una de las variables es: {lasso_regression.coef_}\")\n",
    "# Las columnas son: ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', 'ejection_fraction','high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium','sex', 'smoking', 'time']\n",
    "# Como podemos observar en el valor de los coeficientes, las variables qeu tienen un 0 de coeficiente son las que menos influyen, por esto no se tienen en cuenta. \n",
    "# En nuestro caso son: age, anaemia, creatinine_phosphokinase, ejection_fraction, time, sex y serum_creatinine.\n",
    "\n",
    "# Obtenemos la salida predicha\n",
    "y_pred_lasso = lasso_regression.predict(scaled_test_c)\n",
    "\n",
    "# Calculamos el accuracy\n",
    "accuracy_l = accuracy_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Accuracy del modelo: {accuracy_l}')\n",
    "acc_results_c.append(accuracy_l)\n",
    "\n",
    "# Calculamos la precisión\n",
    "precision_l = metrics.precision_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Precisión del modelo: {precision_l}')\n",
    "prec_results_c.append(precision_l)\n",
    "\n",
    "# Calculamos el recall\n",
    "recall_l = metrics.recall_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Sensibilidad del modelo: {recall_l}')\n",
    "recall_results_c.append(recall_l)\n",
    "\n",
    "# Calculamos el f1 score\n",
    "f1_l = metrics.f1_score(Y_test_c, y_pred_lasso)\n",
    "print(f'F1 score del modelo: {f1_l}')\n",
    "f1_results_c.append(f1_l)\n",
    "\n",
    "# Calculamos el accuracy con validación cruzada\n",
    "acc_cv = cross_val_score(lasso_regression, scaled_train_c, Y_train_c, scoring='accuracy', cv=3)\n",
    "acc_results_c_cv.append(np.mean(acc_cv))\n",
    "print(f'Accuracy del modelo con validación cruzada: {np.mean(acc_cv)}')\n",
    "\n",
    "# Calculamos la precisión con validación cruzada\n",
    "prec_cv = cross_val_score(lasso_regression, scaled_train_c, Y_train_c, scoring='precision', cv=3)\n",
    "prec_results_c_cv.append(np.mean(prec_cv))\n",
    "print(f'Precisión del modelo con validación cruzada: {np.mean(prec_cv)}')\n",
    "\n",
    "# Calculamos la sensibilidad con validación cruzada\n",
    "recall_cv = cross_val_score(lasso_regression, scaled_train_c, Y_train_c, scoring='recall', cv=3)\n",
    "recall_results_c_cv.append(np.mean(recall_cv))\n",
    "print(f'Sensibilidad del modelo con validación cruzada: {np.mean(recall_cv)}')\n",
    "\n",
    "# Calculamos el f1 score con validación cruzada \n",
    "f1_cv = cross_val_score(lasso_regression, scaled_train_c, Y_train_c, scoring='f1', cv=3)\n",
    "f1_results_c_cv.append(np.mean(f1_cv))\n",
    "print(f'F1 score del modelo con validación cruzada: {np.mean(f1_cv)}')\n",
    "\n",
    "#También podemos observar la matriz de confusión\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(Y_test_c, y_pred_lasso), display_labels=[\"No muerte\", \"Muerte\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor valor de C es: 1\n",
      "El mejor valor de l1_ratio es: 0.8\n",
      "El valor de los coeficientes para cada una de las variables es: [[ 0.         -0.10602994  0.         -1.6580195  -0.15305603  0.\n",
      "   1.8239005  -0.10904588  0.28418957  0.         -2.5507928   0.        ]]\n",
      "Accuracy del modelo: 0.8157894736842105\n",
      "Precisión del modelo: 0.9\n",
      "Sensibilidad del modelo: 0.782608695652174\n",
      "F1 score del modelo: 0.8372093023255814\n",
      "Accuracy del modelo con validación cruzada: 0.7279693486590038\n",
      "Precisión del modelo con validación cruzada: 0.75\n",
      "Sensibilidad del modelo con validación cruzada: 0.6007326007326007\n",
      "F1 score del modelo con validación cruzada: 0.6622710622710622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18a8d198f10>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elastic Net\n",
    "# De la misma manera que antes, es necesario utilizar la regresión logistica con parámetros diferentes, en este caso usaremos la penalización elastic net, que es la que se emplea\n",
    "# en el modelo elastic net. En este caso, solo hay un solver que soporte esta penalización\n",
    "elastic_net = LogisticRegression(penalty=\"elasticnet\", solver='saga', l1_ratio=0.5) # INiciamos el modelo con l1_ratio = 0.5, así Ridge y LASSO tienen la misma importancia\n",
    "\n",
    "# Valores de C y l1_ratio\n",
    "parameters = {\"C\":[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20,30], \"l1_ratio\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "\n",
    "# Grid search para elastic net\n",
    "elastic_net_regression = GridSearchCV(elastic_net, parameters, scoring='accuracy', cv=3)\n",
    "elastic_net_regression.fit(scaled_train_c, Y_train_c)\n",
    "\n",
    "print(f\"El mejor valor de C es: {elastic_net_regression.best_params_['C']}\")\n",
    "print(f\"El mejor valor de l1_ratio es: {elastic_net_regression.best_params_['l1_ratio']}\") # Hemos obtenido un valor de l1_ratio de 0.8 lo que indica una mayor importancia de LASSO\n",
    "\n",
    "# Entrenamos\n",
    "\n",
    "elastic_net = LogisticRegression(penalty = \"elasticnet\", solver=\"saga\",C=elastic_net_regression.best_params_['C'], l1_ratio=elastic_net_regression.best_params_['l1_ratio'])\n",
    "elastic_net_regression = elastic_net.fit(scaled_train_c, Y_train_c)\n",
    "\n",
    "print(f\"El valor de los coeficientes para cada una de las variables es: {elastic_net_regression.coef_}\")\n",
    "# Las variables que no se consideran relevantes en este método son: age, creatinine phosphokinase, time y sex\n",
    "\n",
    "# Obtenemos la salida predicha\n",
    "y_pred_elastic_net = elastic_net_regression.predict(scaled_test_c)\n",
    "\n",
    "# Calculamos el accuracy\n",
    "accuracy_e = accuracy_score(Y_test_c, y_pred_elastic_net)\n",
    "print(f'Accuracy del modelo: {accuracy_e}')\n",
    "acc_results_c.append(accuracy_e)\n",
    "\n",
    "# Calculamos la precisión\n",
    "precision_e = metrics.precision_score(Y_test_c, y_pred_elastic_net)\n",
    "print(f'Precisión del modelo: {precision_e}')\n",
    "prec_results_c.append(precision_e)\n",
    "\n",
    "# Calculamos el recall\n",
    "recall_e = metrics.recall_score(Y_test_c, y_pred_elastic_net)\n",
    "print(f'Sensibilidad del modelo: {recall_e}')\n",
    "recall_results_c.append(recall_e)\n",
    "\n",
    "# Calculamos el f1 score\n",
    "f1_e = metrics.f1_score(Y_test_c, y_pred_elastic_net)\n",
    "print(f'F1 score del modelo: {f1_e}')\n",
    "f1_results_c.append(f1_e)\n",
    "\n",
    "# Calculamos el accuracy con validación cruzada\n",
    "acc_cv = cross_val_score(elastic_net_regression, scaled_train_c, Y_train_c, scoring='accuracy', cv=3)\n",
    "acc_results_c_cv.append(np.mean(acc_cv))\n",
    "print(f'Accuracy del modelo con validación cruzada: {np.mean(acc_cv)}')\n",
    "\n",
    "# Calculamos la precisión con validación cruzada\n",
    "prec_cv = cross_val_score(elastic_net_regression, scaled_train_c, Y_train_c, scoring='precision', cv=3)\n",
    "prec_results_c_cv.append(np.mean(prec_cv))\n",
    "print(f'Precisión del modelo con validación cruzada: {np.mean(prec_cv)}')\n",
    "\n",
    "# Calculamos la sensibilidad con validación cruzada\n",
    "recall_cv = cross_val_score(elastic_net_regression, scaled_train_c, Y_train_c, scoring='recall', cv=3)\n",
    "recall_results_c_cv.append(np.mean(recall_cv))\n",
    "print(f'Sensibilidad del modelo con validación cruzada: {np.mean(recall_cv)}')\n",
    "\n",
    "# Calculamos el f1 score con validación cruzada\n",
    "f1_cv = cross_val_score(elastic_net_regression, scaled_train_c, Y_train_c, scoring='f1', cv=3)\n",
    "f1_results_c_cv.append(np.mean(f1_cv))\n",
    "print(f'F1 score del modelo con validación cruzada: {np.mean(f1_cv)}')\n",
    "\n",
    "#También podemos observar la matriz de confusión\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(Y_test_c, y_pred), display_labels=[\"No muerte\", \"Muerte\"]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy en el conjunto de test</th>\n",
       "      <th>Precision en el conjunto de test</th>\n",
       "      <th>Sensibilidad en el conjunto de test</th>\n",
       "      <th>F1 score en el conjunto de test</th>\n",
       "      <th>Accuracy con validación cruzada</th>\n",
       "      <th>Precision con validación cruzada</th>\n",
       "      <th>Sensibilidad con validación cruzada</th>\n",
       "      <th>F1 score con validación cruzada</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Regresión logística lineal</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.760153</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.697802</td>\n",
       "      <td>0.723045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RL multivariable</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.773563</td>\n",
       "      <td>0.832977</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.707172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rigde</th>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.693870</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.424908</td>\n",
       "      <td>0.545528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.727586</td>\n",
       "      <td>0.719195</td>\n",
       "      <td>0.675824</td>\n",
       "      <td>0.687217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elastic Net</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600733</td>\n",
       "      <td>0.662271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy en el conjunto de test  \\\n",
       "Models                                                        \n",
       "Regresión logística lineal                         0.789474   \n",
       "RL multivariable                                   0.815789   \n",
       "Rigde                                              0.631579   \n",
       "Lasso                                              0.815789   \n",
       "Elastic Net                                        0.815789   \n",
       "\n",
       "                            Precision en el conjunto de test  \\\n",
       "Models                                                         \n",
       "Regresión logística lineal                          0.894737   \n",
       "RL multivariable                                    0.944444   \n",
       "Rigde                                               0.909091   \n",
       "Lasso                                               0.900000   \n",
       "Elastic Net                                         0.900000   \n",
       "\n",
       "                            Sensibilidad en el conjunto de test  \\\n",
       "Models                                                            \n",
       "Regresión logística lineal                             0.739130   \n",
       "RL multivariable                                       0.739130   \n",
       "Rigde                                                  0.434783   \n",
       "Lasso                                                  0.782609   \n",
       "Elastic Net                                            0.782609   \n",
       "\n",
       "                            F1 score en el conjunto de test  \\\n",
       "Models                                                        \n",
       "Regresión logística lineal                         0.809524   \n",
       "RL multivariable                                   0.829268   \n",
       "Rigde                                              0.588235   \n",
       "Lasso                                              0.837209   \n",
       "Elastic Net                                        0.837209   \n",
       "\n",
       "                            Accuracy con validación cruzada  \\\n",
       "Models                                                        \n",
       "Regresión logística lineal                         0.760153   \n",
       "RL multivariable                                   0.773563   \n",
       "Rigde                                              0.693870   \n",
       "Lasso                                              0.727586   \n",
       "Elastic Net                                        0.727969   \n",
       "\n",
       "                            Precision con validación cruzada  \\\n",
       "Models                                                         \n",
       "Regresión logística lineal                          0.761111   \n",
       "RL multivariable                                    0.832977   \n",
       "Rigde                                               0.805556   \n",
       "Lasso                                               0.719195   \n",
       "Elastic Net                                         0.750000   \n",
       "\n",
       "                            Sensibilidad con validación cruzada  \\\n",
       "Models                                                            \n",
       "Regresión logística lineal                             0.697802   \n",
       "RL multivariable                                       0.628205   \n",
       "Rigde                                                  0.424908   \n",
       "Lasso                                                  0.675824   \n",
       "Elastic Net                                            0.600733   \n",
       "\n",
       "                            F1 score con validación cruzada  \n",
       "Models                                                       \n",
       "Regresión logística lineal                         0.723045  \n",
       "RL multivariable                                   0.707172  \n",
       "Rigde                                              0.545528  \n",
       "Lasso                                              0.687217  \n",
       "Elastic Net                                        0.662271  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "# Predicciones correctas en el total de predicciones\n",
    "results[\"Accuracy en el conjunto de test\"] = acc_results_c\n",
    "# Predicciones correctas en el total de predicciones positivas\n",
    "results[\"Precision en el conjunto de test\"] = prec_results_c\n",
    "# Predicciones correctas en el total de casos positivos\n",
    "results[\"Sensibilidad en el conjunto de test\"] = recall_results_c\n",
    "# Media armónica entre precision y recall\n",
    "results[\"F1 score en el conjunto de test\"] = f1_results_c\n",
    "\n",
    "results[\"Accuracy con validación cruzada\"] = acc_results_c_cv\n",
    "results[\"Precision con validación cruzada\"] = prec_results_c_cv\n",
    "results[\"Sensibilidad con validación cruzada\"] = recall_results_c_cv\n",
    "results[\"F1 score con validación cruzada\"] = f1_results_c_cv\n",
    "\n",
    "#results\n",
    "results[\"Models\"] = [\"Regresión logística lineal\", \"RL multivariable\",\"Rigde\", \"Lasso\", \"Elastic Net\"]\n",
    "results.set_index(\"Models\", inplace = True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los distintos modelos, podemos obserbar que tanto LASSO como ElasticNet (debido al alto ratio de l1) son los que mejor sensibilidad tienen (que es la métrica que más nos interesa), además tienen el f1 score más alto. Observando todas las matrices de confusión, podemos ver que dichos modelos son muy buenos predictores.\n",
    "Teniendo en cuenta los resultados de la validación cruzada, todas las métricas disminuyen un poco, pero esto tiene sentido ya que en train hemos utilizado un mismo conjunto de datos para entrenar y predecir, haciendo que los modelos estén mejor ajustados para dicho conjunto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor valor de C es: 20\n",
      "El valor de los coeficientes para cada una de las variables es: [[ 1.48789069 -0.35556829  0.44030735 -2.05041628 -0.28218766  0.69867073\n",
      "   3.63359615  0.         -0.60311444  0.         -5.51896923  2.51510721]]\n",
      "Accuracy del modelo: 0.8947368421052632\n",
      "Precisión del modelo: 1.0\n",
      "Sensibilidad del modelo: 0.8\n",
      "F1 score del modelo: 0.888888888888889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18a8f207fa0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Realizamos otra particion para el conjunto de test y el conjunto de train y probamos el modelo LASSO, ya que es el que mejores resultados nos ha dado.\n",
    "\n",
    "X_train_c, X_test_c, Y_train_c, Y_test_c = train_test_split(data_c, data_c_output, test_size=0.3, random_state = 7)\n",
    "\n",
    "# Normalizamos el conjunto de train\n",
    "X_res_train_c = X_train_c.copy()\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "data_minmax_c = scaler.fit_transform(X_res_train_c)\n",
    "\n",
    "scaled_train_c = pd.DataFrame(data_minmax_c, columns=X_res_train_c.columns)\n",
    "\n",
    "# Normalizamos el conjunto de test\n",
    "\n",
    "X_res_test_c = X_test_c.copy()\n",
    "\n",
    "data_minmax_c = scaler.transform(X_res_test_c)\n",
    "\n",
    "scaled_test_c = pd.DataFrame(data_minmax_c, columns=X_res_test_c.columns)\n",
    "\n",
    "# LASSO\n",
    "\n",
    "lasso_ = LogisticRegression(penalty=\"l1\", solver='liblinear')\n",
    "\n",
    "# Valores de C\n",
    "\n",
    "parameters = {\"C\":[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20,30]}\n",
    "\n",
    "# Grid search para lasso regression\n",
    "\n",
    "lasso_regression_ = GridSearchCV(lasso_, parameters, scoring='accuracy', cv=3)\n",
    "lasso_regression_.fit(scaled_train_c, Y_train_c)\n",
    "print(f\"El mejor valor de C es: {lasso_regression_.best_params_['C']}\")\n",
    "\n",
    "# Entrenamos\n",
    "\n",
    "lasso_ = LogisticRegression(penalty = \"l1\", solver = \"liblinear\", C=lasso_regression_.best_params_['C'])\n",
    "lasso_regression_ = lasso_.fit(scaled_train_c, Y_train_c)\n",
    "\n",
    "print(f\"El valor de los coeficientes para cada una de las variables es: {lasso_regression_.coef_}\")\n",
    "\n",
    "# Obtenemos la salida predicha\n",
    "y_pred_lasso = lasso_regression_.predict(scaled_test_c)\n",
    "\n",
    "# Calculamos el accuracy\n",
    "accuracy_l = accuracy_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Accuracy del modelo: {accuracy_l}')\n",
    "\n",
    "# Calculamos la precisión\n",
    "precision_l = metrics.precision_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Precisión del modelo: {precision_l}')\n",
    "\n",
    "# Calculamos el recall\n",
    "recall_l = metrics.recall_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Sensibilidad del modelo: {recall_l}')\n",
    "\n",
    "# Calculamos el f1 score\n",
    "f1_l = metrics.f1_score(Y_test_c, y_pred_lasso)\n",
    "print(f'F1 score del modelo: {f1_l}')\n",
    "\n",
    "#También podemos observar la matriz de confusión\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(Y_test_c, y_pred_lasso), display_labels=[\"No muerte\", \"Muerte\"]).plot()\n",
    "\n",
    "# Como podemos observar, los resultados son muy similares a los obtenidos anteriormente, por lo que podemos decir que el modelo es estable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de la predicción: 0.868421052631579\n",
      "Precisión de la predicción: 0.8947368421052632\n",
      "Sensibilidad de la predicción: 0.85\n",
      "F1 score de la predicción: 0.8717948717948718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x18a8ddd6850>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ahora con el modelo que habiamos entrenado antes, vamos a probar que tal funciona el predictor con los datos de la nueva partición\n",
    "\n",
    "\n",
    "# Obtenemos la salida predicha\n",
    "y_pred_lasso = lasso_regression.predict(scaled_test_c)\n",
    "\n",
    "# Calculamos el accuracy\n",
    "accuracy_l = accuracy_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Accuracy de la predicción: {accuracy_l}')\n",
    "\n",
    "# Calculamos la precisión\n",
    "precision_l = metrics.precision_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Precisión de la predicción: {precision_l}')\n",
    "\n",
    "# Calculamos el recall\n",
    "recall_l = metrics.recall_score(Y_test_c, y_pred_lasso)\n",
    "print(f'Sensibilidad de la predicción: {recall_l}')\n",
    "\n",
    "# Calculamos el f1 score\n",
    "f1_l = metrics.f1_score(Y_test_c, y_pred_lasso)\n",
    "print(f'F1 score de la predicción: {f1_l}')\n",
    "\n",
    "#También podemos observar la matriz de confusión\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(Y_test_c, y_pred_lasso), display_labels=[\"No muerte\", \"Muerte\"]).plot()\n",
    "\n",
    "# Podemos observar que las métricas son bastante buenas, al igual que la matriz de confusión, por lo que podemos concluir finalmente que el modelo es estable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
